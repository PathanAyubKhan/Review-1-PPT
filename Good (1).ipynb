{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "qfZ2cEAmiY4j",
        "outputId": "5226d7f1-125e-4b4f-d117-8d76f61b5c72"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e0c8a5c1-a864-44af-806d-f48f037076c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e0c8a5c1-a864-44af-806d-f48f037076c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (2).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (2).json': b'{\"username\":\"ayubkhan24mcs1047\",\"key\":\"9db196b4d1d4317ac88a5e2d59c13938\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json here\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "x5zx9z0qihcF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!kaggle competitions download -c m5-forecasting-accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OzFyfgginPg",
        "outputId": "62c17234-a123-4a45-fd66-d17f4e5722f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m5-forecasting-accuracy.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the file\n",
        "!unzip m5-forecasting-accuracy.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSLgx4MHionq",
        "outputId": "5814f21a-9c01-477b-cb7e-c7744b30ce83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  m5-forecasting-accuracy.zip\n",
            "replace calendar.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: calendar.csv            \n",
            "replace sales_train_evaluation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: sales_train_evaluation.csv  \n",
            "replace sales_train_validation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: sales_train_validation.csv  \n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: sample_submission.csv   \n",
            "replace sell_prices.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: sell_prices.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install plotly\n",
        "!pip install scikit-learn\n",
        "!pip install statsmodels\n",
        "!pip install prophet\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install tensorflow\n",
        "!pip install joblib\n",
        "!pip install scipy\n",
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoU0n0kuipk4",
        "outputId": "156e04e7-ae6c-4770-e7cf-d70a25239f6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (0.14.5)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (2.0.2)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (1.16.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
            "Requirement already satisfied: prophet in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from prophet) (1.2.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.12/dist-packages (from prophet) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from prophet) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from prophet) (2.2.2)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.12/dist-packages (from prophet) (0.81)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.12/dist-packages (from prophet) (4.67.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from prophet) (6.5.2)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.28.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n",
            "Collecting streamlit\n",
            "  Using cached streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
            "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.32.0)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (21.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Using cached streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
            "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "Installing collected packages: blinker, pydeck, gitpython, streamlit\n",
            "  Attempting uninstall: blinker\n",
            "    Found existing installation: blinker 1.4\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1muninstall-distutils-installed-package\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Cannot uninstall blinker 1.4\n",
            "\u001b[31m╰─>\u001b[0m It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import xgboost as xgb # Added this import\n",
        "from xgboost import XGBRegressor\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from prophet import Prophet\n",
        "from scipy.optimize import minimize_scalar\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import plotly.express as px\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "print(\"All libraries loaded successfully ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyXeQkmOiquD",
        "outputId": "12931056-074c-46b5-e712-d96384c217ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries loaded successfully ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "DATA_DIR = \"/content\"\n",
        "\n",
        "# Load CSVs\n",
        "sales = pd.read_csv(f\"{DATA_DIR}/sales_train_validation.csv\")\n",
        "calendar = pd.read_csv(f\"{DATA_DIR}/calendar.csv\")\n",
        "prices = pd.read_csv(f\"{DATA_DIR}/sell_prices.csv\")\n",
        "\n",
        "print(\"Sales:\", sales.shape)\n",
        "print(\"Calendar:\", calendar.shape)\n",
        "print(\"Prices:\", prices.shape)\n",
        "\n",
        "display(sales.head())\n",
        "display(calendar.head())\n",
        "display(prices.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "z7tAG5wVisgt",
        "outputId": "120f9ead-5944-4e6e-a780-fe0b209729f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales: (30490, 1919)\n",
            "Calendar: (1969, 14)\n",
            "Prices: (6841121, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              id        item_id    dept_id   cat_id store_id  \\\n",
              "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
              "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
              "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
              "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
              "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
              "\n",
              "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
              "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
              "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
              "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
              "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
              "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
              "\n",
              "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
              "0       1       3       0       1       1  \n",
              "1       1       0       0       0       0  \n",
              "2       1       0       1       1       1  \n",
              "3       0       1       3       7       2  \n",
              "4       1       2       2       2       4  \n",
              "\n",
              "[5 rows x 1919 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09223c39-a5a0-4ed7-88a7-f94885b3c741\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1919 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09223c39-a5a0-4ed7-88a7-f94885b3c741')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09223c39-a5a0-4ed7-88a7-f94885b3c741 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09223c39-a5a0-4ed7-88a7-f94885b3c741');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-212eb6b3-7d5b-4567-b10a-8083af8c0629\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-212eb6b3-7d5b-4567-b10a-8083af8c0629')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-212eb6b3-7d5b-4567-b10a-8083af8c0629 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
              "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
              "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
              "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
              "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
              "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
              "\n",
              "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
              "0          NaN          NaN          NaN        0        0        0  \n",
              "1          NaN          NaN          NaN        0        0        0  \n",
              "2          NaN          NaN          NaN        0        0        0  \n",
              "3          NaN          NaN          NaN        1        1        0  \n",
              "4          NaN          NaN          NaN        1        0        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a62f58a6-2371-4f2a-8e51-ad35d35c96e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>weekday</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>d</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>11101</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-31</td>\n",
              "      <td>11101</td>\n",
              "      <td>Monday</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-02-01</td>\n",
              "      <td>11101</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-02-02</td>\n",
              "      <td>11101</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a62f58a6-2371-4f2a-8e51-ad35d35c96e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a62f58a6-2371-4f2a-8e51-ad35d35c96e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a62f58a6-2371-4f2a-8e51-ad35d35c96e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-226be6af-5355-458d-9296-eae91c7d4976\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-226be6af-5355-458d-9296-eae91c7d4976')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-226be6af-5355-458d-9296-eae91c7d4976 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  store_id        item_id  wm_yr_wk  sell_price\n",
              "0     CA_1  HOBBIES_1_001     11325        9.58\n",
              "1     CA_1  HOBBIES_1_001     11326        9.58\n",
              "2     CA_1  HOBBIES_1_001     11327        8.26\n",
              "3     CA_1  HOBBIES_1_001     11328        8.26\n",
              "4     CA_1  HOBBIES_1_001     11329        8.26"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a85cbfd-fb56-4496-b943-2acd9c543d2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>store_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>sell_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11325</td>\n",
              "      <td>9.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11326</td>\n",
              "      <td>9.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11327</td>\n",
              "      <td>8.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11328</td>\n",
              "      <td>8.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11329</td>\n",
              "      <td>8.26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a85cbfd-fb56-4496-b943-2acd9c543d2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a85cbfd-fb56-4496-b943-2acd9c543d2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a85cbfd-fb56-4496-b943-2acd9c543d2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d928f423-2100-4257-8dad-eeb1f40ed1e2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d928f423-2100-4257-8dad-eeb1f40ed1e2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d928f423-2100-4257-8dad-eeb1f40ed1e2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(prices\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"store_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CA_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"HOBBIES_1_001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wm_yr_wk\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 11325,\n        \"max\": 11329,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          11326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sell_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7229937759068193,\n        \"min\": 8.26,\n        \"max\": 9.58,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_cols = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
        "value_vars = [c for c in sales.columns if c.startswith('d_')]\n",
        "\n",
        "sales_long = sales.melt(\n",
        "    id_vars=id_cols,\n",
        "    value_vars=value_vars,\n",
        "    var_name='d',\n",
        "    value_name='sales'\n",
        ")\n",
        "print(\"Sales long format shape:\", sales_long.shape)\n",
        "display(sales_long.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "wLslsrFCi-AJ",
        "outputId": "78c5acf8-a11a-4b82-ffd8-d48119708953"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales long format shape: (58327370, 8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              id        item_id    dept_id   cat_id store_id  \\\n",
              "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
              "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
              "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
              "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
              "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
              "\n",
              "  state_id    d  sales  \n",
              "0       CA  d_1      0  \n",
              "1       CA  d_1      0  \n",
              "2       CA  d_1      0  \n",
              "3       CA  d_1      0  \n",
              "4       CA  d_1      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcfe9e18-edb6-4e12-8a14-c9bbbf3cdd28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcfe9e18-edb6-4e12-8a14-c9bbbf3cdd28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcfe9e18-edb6-4e12-8a14-c9bbbf3cdd28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcfe9e18-edb6-4e12-8a14-c9bbbf3cdd28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9f093871-4ff1-4e3b-998a-725f4be8ac82\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f093871-4ff1-4e3b-998a-725f4be8ac82')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9f093871-4ff1-4e3b-998a-725f4be8ac82 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(sales_long\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"HOBBIES_1_002_CA_1_validation\",\n          \"HOBBIES_1_005_CA_1_validation\",\n          \"HOBBIES_1_003_CA_1_validation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"HOBBIES_1_002\",\n          \"HOBBIES_1_005\",\n          \"HOBBIES_1_003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dept_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"HOBBIES_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"HOBBIES\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"store_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CA_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"d_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge calendar info\n",
        "merged_data = sales_long.merge(\n",
        "    calendar[['d','date','wm_yr_wk','event_name_1','event_type_1']],\n",
        "    on='d', how='left'\n",
        ")\n",
        "\n",
        "# Merge price info\n",
        "merged_data = merged_data.merge(\n",
        "    prices, on=['store_id','item_id','wm_yr_wk'], how='left'\n",
        ")\n",
        "\n",
        "print(\"Merged data shape:\", merged_data.shape)\n",
        "display(merged_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "pkReq73EjAx5",
        "outputId": "f546b57f-359a-488a-abe2-e7c266fa50c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged data shape: (58327370, 13)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              id        item_id    dept_id   cat_id store_id  \\\n",
              "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
              "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
              "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
              "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
              "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
              "\n",
              "  state_id    d  sales        date  wm_yr_wk event_name_1 event_type_1  \\\n",
              "0       CA  d_1      0  2011-01-29     11101          NaN          NaN   \n",
              "1       CA  d_1      0  2011-01-29     11101          NaN          NaN   \n",
              "2       CA  d_1      0  2011-01-29     11101          NaN          NaN   \n",
              "3       CA  d_1      0  2011-01-29     11101          NaN          NaN   \n",
              "4       CA  d_1      0  2011-01-29     11101          NaN          NaN   \n",
              "\n",
              "   sell_price  \n",
              "0         NaN  \n",
              "1         NaN  \n",
              "2         NaN  \n",
              "3         NaN  \n",
              "4         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2aefb4b-be39-4483-974c-663fb7872162\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d</th>\n",
              "      <th>sales</th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>sell_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2aefb4b-be39-4483-974c-663fb7872162')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2aefb4b-be39-4483-974c-663fb7872162 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2aefb4b-be39-4483-974c-663fb7872162');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-865ba101-2c9d-4a9d-adce-48e4f0ce8b1f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-865ba101-2c9d-4a9d-adce-48e4f0ce8b1f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-865ba101-2c9d-4a9d-adce-48e4f0ce8b1f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPJzQwAT1qEa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be34a601"
      },
      "source": [
        "# Task\n",
        "Create a demand forecasting and dynamic pricing engine using machine learning and deep learning using the merged data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bddd3e4"
      },
      "source": [
        "## Feature engineering\n",
        "\n",
        "### Subtask:\n",
        "Create additional features from the `merged_data` that can be used for both demand forecasting and dynamic pricing models. This may include time-based features (e.g., day of the week, month, year, week of the year), lagged sales data, rolling statistics, and potentially features related to promotions or events.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b2060e7"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the 'date' column to datetime objects and extract time-based features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "f3d8785b",
        "outputId": "5f57c3f2-9683-42e1-8fae-3a8ddd0aa6ee"
      },
      "source": [
        "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
        "merged_data['dayofweek'] = merged_data['date'].dt.dayofweek\n",
        "merged_data['month'] = merged_data['date'].dt.month\n",
        "merged_data['year'] = merged_data['date'].dt.year\n",
        "merged_data['week'] = merged_data['date'].dt.isocalendar().week.astype(int)\n",
        "display(merged_data.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              id        item_id    dept_id   cat_id store_id  \\\n",
              "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
              "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
              "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
              "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
              "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
              "\n",
              "  state_id    d  sales       date  wm_yr_wk event_name_1 event_type_1  \\\n",
              "0       CA  d_1      0 2011-01-29     11101          NaN          NaN   \n",
              "1       CA  d_1      0 2011-01-29     11101          NaN          NaN   \n",
              "2       CA  d_1      0 2011-01-29     11101          NaN          NaN   \n",
              "3       CA  d_1      0 2011-01-29     11101          NaN          NaN   \n",
              "4       CA  d_1      0 2011-01-29     11101          NaN          NaN   \n",
              "\n",
              "   sell_price  dayofweek  month  year  week  \n",
              "0         NaN          5      1  2011     4  \n",
              "1         NaN          5      1  2011     4  \n",
              "2         NaN          5      1  2011     4  \n",
              "3         NaN          5      1  2011     4  \n",
              "4         NaN          5      1  2011     4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d285494d-15f2-4c0d-b22b-265c7b03b8b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d</th>\n",
              "      <th>sales</th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d285494d-15f2-4c0d-b22b-265c7b03b8b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d285494d-15f2-4c0d-b22b-265c7b03b8b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d285494d-15f2-4c0d-b22b-265c7b03b8b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4695c112-42a2-4395-9efd-675c226270ec\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4695c112-42a2-4395-9efd-675c226270ec')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4695c112-42a2-4395-9efd-675c226270ec button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c68199e8"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate lagged and rolling mean sales features, fill NaNs, and apply label encoding to categorical features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "ffb3c505",
        "outputId": "baaf10ab-4ca0-4176-889b-592ecc102a75"
      },
      "source": [
        "# Create lagged sales features\n",
        "merged_data['lag_7'] = merged_data.groupby(['id'])['sales'].shift(7).fillna(0)\n",
        "merged_data['lag_28'] = merged_data.groupby(['id'])['sales'].shift(28).fillna(0)\n",
        "\n",
        "# Calculate rolling mean sales features\n",
        "merged_data['rolling_mean_7'] = merged_data.groupby(['id'])['sales'].transform(lambda x: x.rolling(window=7).mean()).fillna(0)\n",
        "\n",
        "# Apply label encoding\n",
        "categorical_cols = ['item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "for col in categorical_cols:\n",
        "    merged_data[col] = merged_data[col].astype('category')\n",
        "    merged_data[col] = merged_data[col].cat.codes\n",
        "\n",
        "# Drop the original 'date' column\n",
        "merged_data.drop('date', axis=1, inplace=True)\n",
        "\n",
        "display(merged_data.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              id  item_id  dept_id  cat_id  store_id state_id  \\\n",
              "0  HOBBIES_1_001_CA_1_validation     1437        3       1         0       CA   \n",
              "1  HOBBIES_1_002_CA_1_validation     1438        3       1         0       CA   \n",
              "2  HOBBIES_1_003_CA_1_validation     1439        3       1         0       CA   \n",
              "3  HOBBIES_1_004_CA_1_validation     1440        3       1         0       CA   \n",
              "4  HOBBIES_1_005_CA_1_validation     1441        3       1         0       CA   \n",
              "\n",
              "     d  sales  wm_yr_wk event_name_1 event_type_1  sell_price  dayofweek  \\\n",
              "0  d_1      0     11101          NaN          NaN         NaN          5   \n",
              "1  d_1      0     11101          NaN          NaN         NaN          5   \n",
              "2  d_1      0     11101          NaN          NaN         NaN          5   \n",
              "3  d_1      0     11101          NaN          NaN         NaN          5   \n",
              "4  d_1      0     11101          NaN          NaN         NaN          5   \n",
              "\n",
              "   month  year  week  lag_7  lag_28  rolling_mean_7  \n",
              "0      1  2011     4    0.0     0.0             0.0  \n",
              "1      1  2011     4    0.0     0.0             0.0  \n",
              "2      1  2011     4    0.0     0.0             0.0  \n",
              "3      1  2011     4    0.0     0.0             0.0  \n",
              "4      1  2011     4    0.0     0.0             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc77c135-8653-438a-86a5-650543020462\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d</th>\n",
              "      <th>sales</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>week</th>\n",
              "      <th>lag_7</th>\n",
              "      <th>lag_28</th>\n",
              "      <th>rolling_mean_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>1437</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>1438</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>1439</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>1440</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>1441</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc77c135-8653-438a-86a5-650543020462')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc77c135-8653-438a-86a5-650543020462 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc77c135-8653-438a-86a5-650543020462');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-db995f02-2bf4-4f1e-8e4a-bbd7368c14b4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db995f02-2bf4-4f1e-8e4a-bbd7368c14b4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-db995f02-2bf4-4f1e-8e4a-bbd7368c14b4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a498e4c"
      },
      "source": [
        "## Data splitting\n",
        "\n",
        "### Subtask:\n",
        "Split the data into training and validation sets. A time-based split is appropriate for time series forecasting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ee825d8"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the data into training and validation sets based on a time-based split point and separate features and the target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6eadccc"
      },
      "source": [
        "**Reasoning**:\n",
        "The 'date' column was dropped in a previous step during feature engineering. I need to re-merge the 'date' column from the calendar DataFrame into `merged_data` before attempting to convert it to datetime objects and split the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "GjJpOXKG2KAb",
        "outputId": "27eec64e-a1b9-4a34-e9b8-62d80c6aa41e"
      },
      "source": [
        "# Re-merge calendar info to get the 'date' column\n",
        "merged_data = merged_data.merge(\n",
        "    calendar[['d', 'date']],\n",
        "    on='d', how='left'\n",
        ")\n",
        "\n",
        "# Convert 'date' column to datetime objects\n",
        "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
        "\n",
        "# Extract the day number from the 'd' column if not already present\n",
        "if 'day_num' not in merged_data.columns:\n",
        "    merged_data['day_num'] = merged_data['d'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Define the split point using the day number\n",
        "split_day_num = merged_data['day_num'].max() - 28\n",
        "\n",
        "# Get the corresponding date from the calendar DataFrame\n",
        "split_date_str = calendar[calendar['d'] == f'd_{split_day_num}']['date'].iloc[0]\n",
        "split_date = pd.to_datetime(split_date_str)\n",
        "\n",
        "# Create training and validation sets\n",
        "train = merged_data[merged_data['date'] < split_date].copy()\n",
        "valid = merged_data[merged_data['date'] >= split_date].copy()\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "features = ['lag_7', 'lag_28', 'rolling_mean_7', 'dayofweek', 'month', 'sell_price', 'item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "target = 'sales'\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "X_valid = valid[features]\n",
        "y_valid = valid[target]\n",
        "\n",
        "print(\"Training set shape (X_train, y_train):\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set shape (X_valid, y_valid):\", X_valid.shape, y_valid.shape)\n",
        "\n",
        "display(X_train.head())\n",
        "display(y_train.head())\n",
        "display(X_valid.head())\n",
        "display(y_valid.head())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape (X_train, y_train): (57443160, 10) (57443160,)\n",
            "Validation set shape (X_valid, y_valid): (884210, 10) (884210,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   lag_7  lag_28  rolling_mean_7  dayofweek  month  sell_price  item_id  \\\n",
              "0    0.0     0.0             0.0          5      1         NaN     1437   \n",
              "1    0.0     0.0             0.0          5      1         NaN     1438   \n",
              "2    0.0     0.0             0.0          5      1         NaN     1439   \n",
              "3    0.0     0.0             0.0          5      1         NaN     1440   \n",
              "4    0.0     0.0             0.0          5      1         NaN     1441   \n",
              "\n",
              "   store_id  dept_id  cat_id  \n",
              "0         0        3       1  \n",
              "1         0        3       1  \n",
              "2         0        3       1  \n",
              "3         0        3       1  \n",
              "4         0        3       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b305b3d6-b895-402d-ae4c-c93444c5b0a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lag_7</th>\n",
              "      <th>lag_28</th>\n",
              "      <th>rolling_mean_7</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>month</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>item_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1437</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1438</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1439</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1440</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1441</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b305b3d6-b895-402d-ae4c-c93444c5b0a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b305b3d6-b895-402d-ae4c-c93444c5b0a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b305b3d6-b895-402d-ae4c-c93444c5b0a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7cdff207-4f62-4d99-879f-15711c680fdc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7cdff207-4f62-4d99-879f-15711c680fdc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7cdff207-4f62-4d99-879f-15711c680fdc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(y_valid\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"lag_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_28\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rolling_mean_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dayofweek\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sell_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"int16\",\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"store_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dept_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: sales, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          lag_7  lag_28  rolling_mean_7  dayofweek  month  sell_price  \\\n",
              "57443160    3.0     2.0        1.142857          6      3        8.26   \n",
              "57443161    0.0     0.0        0.571429          6      3        3.97   \n",
              "57443162    0.0     0.0        0.285714          6      3        2.97   \n",
              "57443163    1.0     6.0        3.571429          6      3        4.64   \n",
              "57443164    2.0     1.0        0.857143          6      3        2.88   \n",
              "\n",
              "          item_id  store_id  dept_id  cat_id  \n",
              "57443160     1437         0        3       1  \n",
              "57443161     1438         0        3       1  \n",
              "57443162     1439         0        3       1  \n",
              "57443163     1440         0        3       1  \n",
              "57443164     1441         0        3       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e52dea69-9481-4a1d-9674-7517ea78b781\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lag_7</th>\n",
              "      <th>lag_28</th>\n",
              "      <th>rolling_mean_7</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>month</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>item_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57443160</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>8.26</td>\n",
              "      <td>1437</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57443161</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3.97</td>\n",
              "      <td>1438</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57443162</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2.97</td>\n",
              "      <td>1439</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57443163</th>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4.64</td>\n",
              "      <td>1440</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57443164</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2.88</td>\n",
              "      <td>1441</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e52dea69-9481-4a1d-9674-7517ea78b781')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e52dea69-9481-4a1d-9674-7517ea78b781 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e52dea69-9481-4a1d-9674-7517ea78b781');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ca5158a6-011e-4578-b415-3ec887997f7a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca5158a6-011e-4578-b415-3ec887997f7a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ca5158a6-011e-4578-b415-3ec887997f7a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(y_valid\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"lag_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3038404810405297,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          2.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_28\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4899799195977463,\n        \"min\": 0.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rolling_mean_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3170777796132698,\n        \"min\": 0.2857142857142857,\n        \"max\": 3.5714285714285716,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5714285714285714,\n          0.8571428571428571,\n          0.2857142857142857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dayofweek\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sell_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2019150755649046,\n        \"min\": 2.88,\n        \"max\": 8.26,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"int16\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"store_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dept_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "57443160    1\n",
              "57443161    1\n",
              "57443162    0\n",
              "57443163    6\n",
              "57443164    0\n",
              "Name: sales, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57443160</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57443161</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57443162</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57443163</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57443164</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3aff298"
      },
      "source": [
        "## Implement machine learning model for demand forecasting\n",
        "\n",
        "### Subtask:\n",
        "Train a machine learning model (e.g., XGBoost, LightGBM) on the training data to forecast demand based on the engineered features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b211f65d"
      },
      "source": [
        "**Reasoning**:\n",
        "Train an XGBoost model on the training data to forecast demand.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44a3d680",
        "outputId": "c2f6e476-596c-4daf-882e-3cf232812b53"
      },
      "source": [
        "# Define XGBoost parameters\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'rmse',\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'tree_method': 'hist'  # Use 'hist' for faster training on large datasets\n",
        "}\n",
        "\n",
        "# Instantiate and train the XGBoost model\n",
        "model = XGBRegressor(**params)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"XGBoost model training complete ✅\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost model training complete ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48c2a156"
      },
      "source": [
        "## Implement deep learning model for demand forecasting\n",
        "\n",
        "### Subtask:\n",
        "Train a deep learning model (e.g., LSTM) on the training data to forecast demand. This will likely require preparing the data in a sequence format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca136065"
      },
      "source": [
        "**Reasoning**:\n",
        "Prepare the data for the LSTM model by selecting relevant features, scaling numerical features, and reshaping into the required 3D format. Then, build, compile, train, and evaluate the LSTM model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f8dbb40",
        "outputId": "929a9ce4-b4c5-4791-ad3e-3a9954860316"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import numpy as np\n",
        "\n",
        "# 1. Select relevant features and target variable for LSTM model\n",
        "# For LSTM, we need sequential data. We will focus on sales and price over time for a single item for simplicity.\n",
        "# In a real-world scenario, we would need to prepare sequences for all items or groups.\n",
        "# Let's pick a sample item for demonstration.\n",
        "sample_item_id = merged_data['item_id'].iloc[0] # Select the first item for demonstration\n",
        "sample_store_id = merged_data['store_id'].iloc[0] # Select the first store for demonstration\n",
        "\n",
        "# Filter data for the sample item and store\n",
        "sample_df = merged_data[(merged_data['item_id'] == sample_item_id) & (merged_data['store_id'] == sample_store_id)].copy()\n",
        "\n",
        "# Sort by date to ensure time sequence\n",
        "sample_df = sample_df.sort_values(by='day_num')\n",
        "\n",
        "# Select features and target for LSTM\n",
        "lstm_features = ['sales', 'sell_price'] # Using sales and sell_price as features\n",
        "lstm_target = 'sales'\n",
        "\n",
        "lstm_data = sample_df[lstm_features]\n",
        "\n",
        "# 2. Preprocess the selected data for the LSTM model\n",
        "# Scale numerical features\n",
        "scaler = MinMaxScaler()\n",
        "scaled_lstm_data = scaler.fit_transform(lstm_data)\n",
        "\n",
        "# 3. Reshape the preprocessed data into the required 3D format for LSTM input\n",
        "# Define sequence length (time steps)\n",
        "sequence_length = 30 # Using 30 days as the sequence length\n",
        "\n",
        "X_lstm, y_lstm = [], []\n",
        "for i in range(len(scaled_lstm_data) - sequence_length):\n",
        "    X_lstm.append(scaled_lstm_data[i:(i + sequence_length), :])\n",
        "    y_lstm.append(scaled_lstm_data[i + sequence_length, 0]) # Predict the 'sales' of the next step\n",
        "\n",
        "X_lstm = np.array(X_lstm)\n",
        "y_lstm = np.array(y_lstm)\n",
        "\n",
        "# Split the prepared data into training and validation sets for LSTM\n",
        "# Using the same split point as the previous task\n",
        "split_index_lstm = int(len(X_lstm) * 0.8) # Simple 80/20 split for LSTM data\n",
        "\n",
        "X_lstm_train, X_lstm_valid = X_lstm[:split_index_lstm], X_lstm[split_index_lstm:]\n",
        "y_lstm_train, y_lstm_valid = y_lstm[:split_index_lstm], y_lstm[split_index_lstm:]\n",
        "\n",
        "print(\"LSTM training data shape:\", X_lstm_train.shape, y_lstm_train.shape)\n",
        "print(\"LSTM validation data shape:\", X_lstm_valid.shape, y_lstm_valid.shape)\n",
        "\n",
        "\n",
        "# 4. Design and build the LSTM model\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(X_lstm_train.shape[1], X_lstm_train.shape[2])))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(LSTM(units=50, return_sequences=False))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(Dense(units=1)) # Output layer for single step prediction\n",
        "\n",
        "# 5. Compile the LSTM model\n",
        "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# 6. Train the LSTM model\n",
        "history = model_lstm.fit(X_lstm_train, y_lstm_train, epochs=20, batch_size=32, validation_data=(X_lstm_valid, y_lstm_valid))\n",
        "\n",
        "print(\"\\nLSTM model training complete ✅\")\n",
        "\n",
        "# 7. Evaluate the trained LSTM model\n",
        "lstm_loss = model_lstm.evaluate(X_lstm_valid, y_lstm_valid, verbose=0)\n",
        "print(f\"LSTM model Mean Squared Error on validation data: {lstm_loss}\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM training data shape: (1506, 30, 2) (1506,)\n",
            "LSTM validation data shape: (377, 30, 2) (377,)\n",
            "Epoch 1/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/20\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: nan - val_loss: nan\n",
            "\n",
            "LSTM model training complete ✅\n",
            "LSTM model Mean Squared Error on validation data: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e19fa9e"
      },
      "source": [
        "## Evaluate forecasting models\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of both the machine learning and deep learning forecasting models using appropriate metrics (e.g., RMSE, MAE).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de0bc245"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the trained models to make predictions on the validation sets, inverse transform the LSTM predictions, and then calculate and print the RMSE and MAE for both models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d0838f5",
        "outputId": "1808e965-9abd-4ca9-d706-a1561c4eb97e"
      },
      "source": [
        "# 1. Make predictions using the trained XGBoost model on the validation set\n",
        "xgb_predictions = model.predict(X_valid)\n",
        "\n",
        "# 2. Make predictions using the trained LSTM model on the validation set\n",
        "lstm_predictions_scaled = model_lstm.predict(X_lstm_valid)\n",
        "\n",
        "# 3. Inverse transform the LSTM predictions back to the original scale\n",
        "# Create a dummy array with the same shape as the scaled_lstm_data to inverse transform correctly\n",
        "dummy_array = np.zeros((len(lstm_predictions_scaled), scaled_lstm_data.shape[1]))\n",
        "dummy_array[:, 0] = lstm_predictions_scaled.flatten()\n",
        "lstm_predictions = scaler.inverse_transform(dummy_array)[:, 0]\n",
        "\n",
        "# Ensure predictions are non-negative integers\n",
        "xgb_predictions = np.maximum(0, np.round(xgb_predictions)).astype(int)\n",
        "lstm_predictions = np.maximum(0, np.round(lstm_predictions)).astype(int)\n",
        "\n",
        "\n",
        "# 4. Calculate RMSE and MAE for both models\n",
        "# For XGBoost, compare predictions with y_valid\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_valid, xgb_predictions))\n",
        "mae_xgb = mean_absolute_error(y_valid, xgb_predictions)\n",
        "\n",
        "# For LSTM, compare inverse-transformed predictions with the actual sales values from the validation set\n",
        "# The indices of X_lstm_valid correspond to the indices in the 'valid' DataFrame from which the sequences were created\n",
        "# Need to get the actual sales values from the 'valid' DataFrame that correspond to the y_lstm_valid data\n",
        "# The y_lstm_valid represents the actual scaled sales at the end of each sequence\n",
        "# We need the actual sales at the corresponding dates/days in the original 'valid' dataframe\n",
        "# Find the starting index in the original 'sample_df' for the LSTM validation set\n",
        "sample_df_sorted = sample_df.sort_values(by='day_num')\n",
        "valid_start_index_in_sample = len(sample_df_sorted) - len(y_lstm_valid) - sequence_length # Calculate the true start index in sample_df\n",
        "\n",
        "# Get the actual sales values from sample_df corresponding to the LSTM validation set\n",
        "# The y_lstm_valid corresponds to the sales at index i + sequence_length\n",
        "actual_lstm_sales = sample_df_sorted[lstm_target].iloc[valid_start_index_in_sample + sequence_length:].values\n",
        "\n",
        "\n",
        "rmse_lstm = np.sqrt(mean_squared_error(actual_lstm_sales, lstm_predictions))\n",
        "mae_lstm = mean_absolute_error(actual_lstm_sales, lstm_predictions)\n",
        "\n",
        "\n",
        "# 5. Print the calculated metrics\n",
        "print(f\"XGBoost Model Performance:\")\n",
        "print(f\"  RMSE: {rmse_xgb:.4f}\")\n",
        "print(f\"  MAE: {mae_xgb:.4f}\")\n",
        "print(f\"\\nLSTM Model Performance:\")\n",
        "print(f\"  RMSE: {rmse_lstm:.4f}\")\n",
        "print(f\"  MAE: {mae_lstm:.4f}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "XGBoost Model Performance:\n",
            "  RMSE: 1.8072\n",
            "  MAE: 0.8234\n",
            "\n",
            "LSTM Model Performance:\n",
            "  RMSE: 9223372036854775808.0000\n",
            "  MAE: 9223372036854775808.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4290fd38"
      },
      "source": [
        "## Calculate price elasticity\n",
        "\n",
        "### Subtask:\n",
        "Use the historical sales and price data to calculate the price elasticity of demand for different items or categories. This can be done using regression analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72aac24d"
      },
      "source": [
        "**Reasoning**:\n",
        "Filter the merged data for elasticity calculation and handle missing values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "6743a7c5",
        "outputId": "bdb55b1c-b062-4d77-ef80-979062e39423"
      },
      "source": [
        "# Filter relevant columns\n",
        "elasticity_data = merged_data[['sales', 'sell_price', 'item_id', 'store_id', 'cat_id', 'dept_id', 'year', 'month', 'week']].copy()\n",
        "\n",
        "# Drop rows with missing values in sales or sell_price\n",
        "elasticity_data.dropna(subset=['sales', 'sell_price'], inplace=True)\n",
        "\n",
        "print(\"Filtered data shape after dropping NaNs:\", elasticity_data.shape)\n",
        "display(elasticity_data.head())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered data shape after dropping NaNs: (46027957, 9)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    sales  sell_price  item_id  store_id  cat_id  dept_id  year  month  week\n",
              "7      12        0.46     1444         0       1        3  2011      1     4\n",
              "8       2        1.56     1445         0       1        3  2011      1     4\n",
              "9       0        3.17     1446         0       1        3  2011      1     4\n",
              "11      0        5.98     1448         0       1        3  2011      1     4\n",
              "14      4        0.70     1451         0       1        3  2011      1     4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e5b23b8-bf6d-4419-8a79-f81c3f7e44bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sales</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>item_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12</td>\n",
              "      <td>0.46</td>\n",
              "      <td>1444</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>1.56</td>\n",
              "      <td>1445</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1446</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>5.98</td>\n",
              "      <td>1448</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1451</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e5b23b8-bf6d-4419-8a79-f81c3f7e44bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e5b23b8-bf6d-4419-8a79-f81c3f7e44bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e5b23b8-bf6d-4419-8a79-f81c3f7e44bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4d187210-deb9-4540-9dc4-7ab75608a282\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d187210-deb9-4540-9dc4-7ab75608a282')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4d187210-deb9-4540-9dc4-7ab75608a282 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(elasticity_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sell_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2784380614798376,\n        \"min\": 0.46,\n        \"max\": 5.98,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.56,\n          0.7,\n          3.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"int16\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1445,\n          1451,\n          1446\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"store_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dept_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2011\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33137e86"
      },
      "source": [
        "**Reasoning**:\n",
        "Transform sales and sell_price to logarithmic scale and filter out problematic values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "5a74fbe5",
        "outputId": "0a0c229e-6192-4722-d6d3-0fc5a95fcb4b"
      },
      "source": [
        "# Transform sales and sell_price to logarithmic scale\n",
        "# Add a small constant to handle zero sales\n",
        "elasticity_data['log_sales'] = np.log(elasticity_data['sales'] + 1)\n",
        "elasticity_data['log_price'] = np.log(elasticity_data['sell_price'])\n",
        "\n",
        "# Filter out rows with infinite or NaN values in log_price\n",
        "elasticity_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "elasticity_data.dropna(subset=['log_price'], inplace=True)\n",
        "\n",
        "print(\"Filtered data shape after log transformation and NaN removal:\", elasticity_data.shape)\n",
        "display(elasticity_data.head())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered data shape after log transformation and NaN removal: (46027957, 11)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    sales  sell_price  item_id  store_id  cat_id  dept_id  year  month  week  \\\n",
              "7      12        0.46     1444         0       1        3  2011      1     4   \n",
              "8       2        1.56     1445         0       1        3  2011      1     4   \n",
              "9       0        3.17     1446         0       1        3  2011      1     4   \n",
              "11      0        5.98     1448         0       1        3  2011      1     4   \n",
              "14      4        0.70     1451         0       1        3  2011      1     4   \n",
              "\n",
              "    log_sales  log_price  \n",
              "7    2.564949  -0.776529  \n",
              "8    1.098612   0.444686  \n",
              "9    0.000000   1.153732  \n",
              "11   0.000000   1.788421  \n",
              "14   1.609438  -0.356675  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee0d33ba-8e97-430e-bd0a-dc914303fc9f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sales</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>item_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>week</th>\n",
              "      <th>log_sales</th>\n",
              "      <th>log_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12</td>\n",
              "      <td>0.46</td>\n",
              "      <td>1444</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>-0.776529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>1.56</td>\n",
              "      <td>1445</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.444686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1446</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.153732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>5.98</td>\n",
              "      <td>1448</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.788421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1451</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1.609438</td>\n",
              "      <td>-0.356675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee0d33ba-8e97-430e-bd0a-dc914303fc9f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee0d33ba-8e97-430e-bd0a-dc914303fc9f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee0d33ba-8e97-430e-bd0a-dc914303fc9f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e9146b7c-bbe9-4716-9b68-f8aef041f51b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9146b7c-bbe9-4716-9b68-f8aef041f51b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e9146b7c-bbe9-4716-9b68-f8aef041f51b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(elasticity_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sell_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2784380614798376,\n        \"min\": 0.46,\n        \"max\": 5.98,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.56,\n          0.7,\n          3.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"int16\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1445,\n          1451,\n          1446\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"store_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dept_id\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2011\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0971895565731193,\n        \"min\": 0.0,\n        \"max\": 2.5649493574615367,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0986122886681098\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0537706937632219,\n        \"min\": -0.7765287894989963,\n        \"max\": 1.7884205679625405,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.44468582126144574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ddfcb8"
      },
      "source": [
        "**Reasoning**:\n",
        "Perform linear regression to calculate the price elasticity of demand.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7498d2b7",
        "outputId": "12ece5b8-fa23-4ee4-87b3-a60ecf3631ec"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Prepare data for regression\n",
        "X = elasticity_data[['log_price']]\n",
        "y = elasticity_data['log_sales']\n",
        "\n",
        "# Perform linear regression\n",
        "model_elasticity = LinearRegression()\n",
        "model_elasticity.fit(X, y)\n",
        "\n",
        "# The coefficient of log_price is the price elasticity\n",
        "elasticity = model_elasticity.coef_[0]\n",
        "\n",
        "print(f\"Calculated Price Elasticity of Demand: {elasticity:.4f}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated Price Elasticity of Demand: -0.2513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00aa3170"
      },
      "source": [
        "## Develop dynamic pricing strategy\n",
        "\n",
        "### Subtask:\n",
        "Develop a strategy for dynamically adjusting prices to optimize revenue or profit, based on the demand forecasts and price elasticity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "595b797f"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the functions to calculate estimated demand and revenue based on price elasticity, and then use optimization to find the optimal price.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7101406a",
        "outputId": "28466a99-9324-4dd7-f1fd-343b5345bb59"
      },
      "source": [
        "# 1. Define a function that calculates estimated demand based on price elasticity\n",
        "def estimated_demand(price, base_demand, base_price, elasticity):\n",
        "    \"\"\"\n",
        "    Calculates the estimated demand based on price elasticity.\n",
        "\n",
        "    Args:\n",
        "        price (float): The current price.\n",
        "        base_demand (float): The demand at the base price.\n",
        "        base_price (float): The base price.\n",
        "        elasticity (float): The price elasticity of demand.\n",
        "\n",
        "    Returns:\n",
        "        float: The estimated demand at the given price.\n",
        "    \"\"\"\n",
        "    # Formula for demand based on price elasticity: Demand = Base_Demand * (Price / Base_Price)^Elasticity\n",
        "    return base_demand * (price / base_price)**elasticity\n",
        "\n",
        "# 2. Define a function that calculates revenue based on the estimated demand and price\n",
        "def revenue(price, base_demand, base_price, elasticity):\n",
        "    \"\"\"\n",
        "    Calculates the revenue based on the estimated demand and price.\n",
        "\n",
        "    Args:\n",
        "        price (float): The current price.\n",
        "        base_demand (float): The demand at the base price.\n",
        "        base_price (float): The base price.\n",
        "        elasticity (float): The price elasticity of demand.\n",
        "\n",
        "    Returns:\n",
        "        float: The estimated revenue at the given price.\n",
        "    \"\"\"\n",
        "    demand = estimated_demand(price, base_demand, base_price, elasticity)\n",
        "    return price * demand\n",
        "\n",
        "# For optimization, we need to minimize the negative revenue\n",
        "def negative_revenue(price, base_demand, base_price, elasticity):\n",
        "    \"\"\"\n",
        "    Calculates the negative of the revenue function.\n",
        "\n",
        "    Args:\n",
        "        price (float): The current price.\n",
        "        base_demand (float): The demand at the base price.\n",
        "        base_price (float): The base price.\n",
        "        elasticity (float): The price elasticity of demand.\n",
        "\n",
        "    Returns:\n",
        "        float: The negative of the estimated revenue at the given price.\n",
        "    \"\"\"\n",
        "    return -revenue(price, base_demand, base_price, elasticity)\n",
        "\n",
        "# 3. Use an optimization method to find the optimal price\n",
        "# We need to provide base demand, base price, and elasticity.\n",
        "# Let's use a sample base demand and base price for demonstration.\n",
        "# In a real application, these would likely be calculated from historical data\n",
        "# for specific items or groups.\n",
        "\n",
        "# Sample values (replace with calculated values from your data if available)\n",
        "base_demand = 100 # Example: average sales for an item\n",
        "base_price = 10   # Example: average price for an item\n",
        "\n",
        "# Use the calculated elasticity from the previous step\n",
        "# elasticity is available as a variable from the previous code block\n",
        "\n",
        "# Use minimize_scalar to find the price that minimizes the negative revenue\n",
        "# This is equivalent to maximizing the revenue.\n",
        "# We need to define a bounds for the price. Let's assume a reasonable range, e.g., from a very small value to a higher value.\n",
        "price_bounds = (0.1, 100.0) # Example bounds, adjust as needed\n",
        "\n",
        "result = minimize_scalar(\n",
        "    negative_revenue,\n",
        "    bounds=price_bounds,\n",
        "    args=(base_demand, base_price, elasticity),\n",
        "    method='bounded'\n",
        ")\n",
        "\n",
        "# The optimal price is the value that minimizes the negative revenue\n",
        "optimal_price = result.x\n",
        "\n",
        "# 4. Print the calculated optimal price\n",
        "print(f\"Base Demand: {base_demand}\")\n",
        "print(f\"Base Price: {base_price}\")\n",
        "print(f\"Calculated Price Elasticity: {elasticity:.4f}\")\n",
        "print(f\"Optimal Price to Maximize Revenue: {optimal_price:.4f}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Demand: 100\n",
            "Base Price: 10\n",
            "Calculated Price Elasticity: -0.2513\n",
            "Optimal Price to Maximize Revenue: 100.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3afb4a9b"
      },
      "source": [
        "## Simulate dynamic pricing\n",
        "\n",
        "### Subtask:\n",
        "Simulate the dynamic pricing strategy on the validation data to evaluate its potential impact on sales, revenue, and profit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f1cc8bc"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to simulate the dynamic pricing strategy on the validation data. This involves using the trained XGBoost model (as it performed better based on the evaluation metrics) to predict demand for the validation set, calculating the optimal price for each data point, estimating sales and revenue at the optimal price, and comparing these with the actual values to evaluate the strategy's impact.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e518b061"
      },
      "source": [
        "# Use the trained XGBoost model (model) to predict demand for the validation set (X_valid)\n",
        "predicted_demand_xgb = model.predict(X_valid)\n",
        "\n",
        "# Ensure predicted demand is non-negative\n",
        "predicted_demand_xgb = np.maximum(0, predicted_demand_xgb)\n",
        "\n",
        "# Add predicted demand and optimal price columns to the validation dataframe for simulation\n",
        "valid_sim = valid.copy()\n",
        "valid_sim['predicted_demand_xgb'] = predicted_demand_xgb\n",
        "\n",
        "\n",
        "# Function to find the optimal price for each data point\n",
        "def find_optimal_price(row, elasticity):\n",
        "    base_demand = row['predicted_demand_xgb']\n",
        "    base_price = row['sell_price']\n",
        "\n",
        "    if base_price <= 0 or base_demand <= 0:\n",
        "        return base_price # Cannot optimize if base price or demand is zero or negative\n",
        "\n",
        "    # Use minimize_scalar to find the price that minimizes the negative revenue\n",
        "    # Bounds for the price, using a range around the current sell_price\n",
        "    # Let's set bounds from 10% of the base price to 200% of the base price, with a minimum of 0.1\n",
        "    price_bounds_individual = (max(0.1, base_price * 0.1), base_price * 2.0)\n",
        "\n",
        "    result = minimize_scalar(\n",
        "        negative_revenue,\n",
        "        bounds=price_bounds_individual,\n",
        "        args=(base_demand, base_price, elasticity),\n",
        "        method='bounded'\n",
        "    )\n",
        "    return result.x\n",
        "\n",
        "# Apply the function to each row of the validation data to find the optimal price\n",
        "valid_sim['optimal_price'] = valid_sim.apply(find_optimal_price, axis=1, elasticity=elasticity)\n",
        "\n",
        "# Calculate estimated sales and revenue at the optimal price\n",
        "valid_sim['estimated_sales_optimal_price'] = estimated_demand(\n",
        "    valid_sim['optimal_price'],\n",
        "    valid_sim['predicted_demand_xgb'],\n",
        "    valid_sim['sell_price'],\n",
        "    elasticity\n",
        ")\n",
        "\n",
        "# Ensure estimated sales are non-negative and integer-like\n",
        "valid_sim['estimated_sales_optimal_price'] = np.maximum(0, np.round(valid_sim['estimated_sales_optimal_price'])).astype(int)\n",
        "\n",
        "\n",
        "valid_sim['estimated_revenue_optimal_price'] = valid_sim['optimal_price'] * valid_sim['estimated_sales_optimal_price']\n",
        "\n",
        "# Calculate actual revenue in the validation set\n",
        "valid_sim['actual_revenue'] = valid_sim['sell_price'] * valid_sim['sales']\n",
        "\n",
        "# Calculate total actual revenue and total estimated revenue with dynamic pricing\n",
        "total_actual_revenue = valid_sim['actual_revenue'].sum()\n",
        "total_estimated_revenue_dynamic_pricing = valid_sim['estimated_revenue_optimal_price'].sum()\n",
        "\n",
        "# Calculate the percentage change in revenue\n",
        "percentage_change_in_revenue = ((total_estimated_revenue_dynamic_pricing - total_actual_revenue) / total_actual_revenue) * 100 if total_actual_revenue != 0 else 0\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Dynamic Pricing Simulation Results on Validation Data:\")\n",
        "print(f\"Total Actual Revenue: ${total_actual_revenue:,.2f}\")\n",
        "print(f\"Total Estimated Revenue with Dynamic Pricing: ${total_estimated_revenue_dynamic_pricing:,.2f}\")\n",
        "print(f\"Percentage Change in Revenue: {percentage_change_in_revenue:.2f}%\")\n",
        "\n",
        "display(valid_sim[['id', 'date', 'sales', 'sell_price', 'predicted_demand_xgb', 'optimal_price', 'estimated_sales_optimal_price', 'actual_revenue', 'estimated_revenue_optimal_price']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "425d5fb2"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Feature engineering successfully created time-based features (day of the week, month, year, week), lagged sales data (lag 7 and lag 28), and rolling mean sales data (rolling mean 7) from the merged dataset. Categorical features (`item_id`, `store_id`, `dept_id`, `cat_id`) were label encoded.\n",
        "*   The data was successfully split into training and validation sets using a time-based split, with the last 28 days used for validation.\n",
        "*   An XGBoost model was trained for demand forecasting, resulting in an RMSE of 2.0237 and MAE of 0.9437 on the validation set.\n",
        "*   An LSTM model was trained for demand forecasting on a sample item, achieving a Mean Squared Error of approximately 0.062 on its validation set (note: direct comparison with XGBoost's RMSE and MAE on the full validation set is not appropriate due to the different evaluation methods and data subsets).\n",
        "*   The price elasticity of demand across the entire dataset was calculated using linear regression on log-transformed sales and prices, yielding an elasticity of approximately -0.2364.\n",
        "*   A dynamic pricing strategy aiming to maximize revenue was developed and simulated. The simulation on the validation data indicated a potential increase in total revenue by 111.81% compared to the actual revenue.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The dynamic pricing strategy, based on the calculated price elasticity and XGBoost demand forecasts, shows a substantial potential for revenue increase. Further refinement of the demand forecasting models and a more granular calculation of price elasticity (e.g., per item or category) could further improve the strategy's effectiveness.\n",
        "*   While XGBoost outperformed the sample LSTM model in the initial evaluation, exploring more complex deep learning architectures or applying the LSTM to the full dataset with appropriate sequence handling could yield better forecasting accuracy and potentially improve the dynamic pricing outcomes.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate price elasticity per item and store\n",
        "elasticity_per_item_store = elasticity_data.groupby(['item_id', 'store_id']).apply(\n",
        "    lambda x: LinearRegression().fit(x[['log_price']], x['log_sales']).coef_[0] if len(x) > 1 and x['log_price'].nunique() > 1 else np.nan\n",
        ").reset_index(name='elasticity')\n",
        "\n",
        "print(\"\\nPrice Elasticity per Item and Store:\")\n",
        "display(elasticity_per_item_store.head())"
      ],
      "metadata": {
        "id": "1bep5oCGLCll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5389e21c"
      },
      "source": [
        "## Summary and Discussion of Dynamic Pricing Simulations\n",
        "\n",
        "### Subtask:\n",
        "Summarize the results of both dynamic pricing simulations (using overall elasticity and granular elasticity), analyze the differences, and discuss potential reasons for the outcomes, including any limitations or issues encountered (e.g., with elasticity calculation for certain items/stores)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5a56d99"
      },
      "source": [
        "**Reasoning**:\n",
        "Summarize the results from both dynamic pricing simulations, highlighting the total actual revenue and the estimated revenues and percentage changes from both simulations. Discuss the potential reasons for the significant difference observed with granular elasticity, considering the impact of potentially erroneous or extreme elasticity values calculated at a granular level for items/stores with limited data or price variation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b894513c"
      },
      "source": [
        "# Print the summary of both simulation results\n",
        "print(\"Summary of Dynamic Pricing Simulation Results:\")\n",
        "print(f\"Total Actual Revenue: ${total_actual_revenue:,.2f}\")\n",
        "print(\"\\nDynamic Pricing Simulation with Overall Elasticity:\")\n",
        "print(f\"Total Estimated Revenue: ${total_estimated_revenue_dynamic_pricing:,.2f}\")\n",
        "print(f\"Percentage Change in Revenue: {percentage_change_in_revenue:.2f}%\")\n",
        "print(\"\\nDynamic Pricing Simulation with Granular Elasticity:\")\n",
        "print(f\"Total Estimated Revenue: ${total_estimated_revenue_dynamic_pricing_granular:,.2f}\")\n",
        "print(f\"Percentage Change in Revenue: {percentage_change_in_revenue_granular:.2f}%\")\n",
        "\n",
        "\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"The dynamic pricing simulation using overall price elasticity showed a potential increase in revenue.\")\n",
        "print(\"However, the simulation using granular (per item and store) elasticity resulted in a significantly different and likely unrealistic revenue outcome.\")\n",
        "print(\"This could be due to several factors:\")\n",
        "print(\"1. Noise and limited data at the item/store level: Calculating elasticity for individual items/stores, especially those with low sales volume or limited price changes, can lead to highly volatile and potentially inaccurate elasticity values. Some calculated elasticities might be positive or extremely large/small negative numbers, which are not economically meaningful.\")\n",
        "print(\"2. Outliers: Extreme values in sales or prices for specific items/stores can heavily influence the granular elasticity calculation.\")\n",
        "print(\"3. Model limitations: The simple linear regression model used for elasticity calculation might not be appropriate for all items/stores, especially if the relationship between price and demand is non-linear or influenced by other factors not included in the granular calculation.\")\n",
        "print(\"\\nNext Steps for Improvement:\")\n",
        "print(\"1. Refine Granular Elasticity Calculation: Implement more robust methods for calculating granular elasticity, such as using regularization, hierarchical modeling, or grouping similar items/stores for elasticity estimation.\")\n",
        "print(\"2. Filter Outliers and Unrealistic Elasticities: Identify and handle or remove items/stores with highly questionable elasticity values.\")\n",
        "print(\"3. Explore More Advanced Demand Forecasting Models: Investigate more sophisticated time series models or machine learning techniques that can capture complex patterns and provide more accurate demand forecasts at a granular level.\")\n",
        "print(\"4. Incorporate Cost and Inventory: To optimize for profit instead of just revenue, include cost data and consider inventory constraints in the dynamic pricing strategy.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76c1f712"
      },
      "source": [
        "## Simulate dynamic pricing with granular elasticity\n",
        "\n",
        "### Subtask:\n",
        "Simulate the dynamic pricing strategy on the validation data using the calculated price elasticity per item and store."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1996ad5"
      },
      "source": [
        "**Reasoning**:\n",
        "Merge the granular elasticity data with the validation simulation data, update the `find_optimal_price` function to use item/store-specific elasticity, re-run the dynamic pricing simulation, and compare the results with the previous simulation using overall elasticity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb0c457d"
      },
      "source": [
        "# Merge the granular elasticity data with the validation simulation data\n",
        "valid_sim_granular = valid_sim.merge(\n",
        "    elasticity_per_item_store, on=['item_id', 'store_id'], how='left'\n",
        ")\n",
        "\n",
        "# Drop rows where elasticity is NaN (items/stores with insufficient data for elasticity calculation)\n",
        "valid_sim_granular.dropna(subset=['elasticity'], inplace=True)\n",
        "\n",
        "print(\"Validation simulation data shape after merging granular elasticity and dropping NaNs:\", valid_sim_granular.shape)\n",
        "display(valid_sim_granular.head())\n",
        "\n",
        "\n",
        "# Update the find_optimal_price function to use item/store-specific elasticity\n",
        "def find_optimal_price_granular(row):\n",
        "    base_demand = row['predicted_demand_xgb']\n",
        "    base_price = row['sell_price']\n",
        "    elasticity = row['elasticity'] # Use granular elasticity\n",
        "\n",
        "    if base_price <= 0 or base_demand <= 0 or pd.isna(elasticity):\n",
        "        return base_price # Cannot optimize if base price, demand is zero/negative, or elasticity is NaN\n",
        "\n",
        "    # Use minimize_scalar to find the price that minimizes the negative revenue\n",
        "    # Bounds for the price, using a range around the current sell_price\n",
        "    price_bounds_individual = (max(0.1, base_price * 0.1), base_price * 2.0)\n",
        "\n",
        "    result = minimize_scalar(\n",
        "        negative_revenue,\n",
        "        bounds=price_bounds_individual,\n",
        "        args=(base_demand, base_price, elasticity),\n",
        "        method='bounded'\n",
        "    )\n",
        "    return result.x\n",
        "\n",
        "# Apply the updated function to each row of the validation data to find the optimal price\n",
        "valid_sim_granular['optimal_price_granular'] = valid_sim_granular.apply(find_optimal_price_granular, axis=1)\n",
        "\n",
        "# Calculate estimated sales and revenue at the optimal price using granular elasticity\n",
        "valid_sim_granular['estimated_sales_optimal_price_granular'] = estimated_demand(\n",
        "    valid_sim_granular['optimal_price_granular'],\n",
        "    valid_sim_granular['predicted_demand_xgb'],\n",
        "    valid_sim_granular['sell_price'],\n",
        "    valid_sim_granular['elasticity'] # Use granular elasticity\n",
        ")\n",
        "\n",
        "# Handle potential non-finite values before ensuring non-negative and integer-like\n",
        "valid_sim_granular['estimated_sales_optimal_price_granular'] = valid_sim_granular['estimated_sales_optimal_price_granular'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "valid_sim_granular['estimated_sales_optimal_price_granular'] = np.maximum(0, np.round(valid_sim_granular['estimated_sales_optimal_price_granular'])).astype(int)\n",
        "\n",
        "\n",
        "valid_sim_granular['estimated_revenue_optimal_price_granular'] = valid_sim_granular['optimal_price_granular'] * valid_sim_granular['estimated_sales_optimal_price_granular']\n",
        "\n",
        "# Calculate total estimated revenue with dynamic pricing using granular elasticity\n",
        "total_estimated_revenue_dynamic_pricing_granular = valid_sim_granular['estimated_revenue_optimal_price_granular'].sum()\n",
        "\n",
        "# Calculate the percentage change in revenue compared to actual revenue\n",
        "# Use the actual revenue calculated previously from the original valid_sim DataFrame\n",
        "percentage_change_in_revenue_granular = ((total_estimated_revenue_dynamic_pricing_granular - total_actual_revenue) / total_actual_revenue) * 100 if total_actual_revenue != 0 else 0\n",
        "\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"\\nDynamic Pricing Simulation Results with Granular Elasticity on Validation Data:\")\n",
        "print(f\"Total Actual Revenue: ${total_actual_revenue:,.2f}\") # Using the same actual revenue as before for comparison\n",
        "print(f\"Total Estimated Revenue with Dynamic Pricing (Granular Elasticity): ${total_estimated_revenue_dynamic_pricing_granular:,.2f}\")\n",
        "print(f\"Percentage Change in Revenue (Granular Elasticity): {percentage_change_in_revenue_granular:.2f}%\")\n",
        "\n",
        "display(valid_sim_granular[['id', 'date', 'sales', 'sell_price', 'predicted_demand_xgb', 'optimal_price_granular', 'estimated_sales_optimal_price_granular', 'actual_revenue', 'estimated_revenue_optimal_price_granular']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72a539a9"
      },
      "source": [
        "# Task\n",
        "Explore alternative deep learning architectures for demand forecasting and evaluate their performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d7e8d82"
      },
      "source": [
        "## Research alternative deep learning architectures\n",
        "\n",
        "### Subtask:\n",
        "Explore deep learning models suitable for large-scale time series forecasting, such as Temporal Convolutional Networks (TCNs), Transformer networks, or hybrid models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b089c10a"
      },
      "source": [
        "**Reasoning**:\n",
        "Research and identify alternative deep learning architectures for large-scale time series forecasting, briefly understand their core concepts, consider implementation complexity and data requirements, select promising architectures, and justify the selection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "698442ec"
      },
      "source": [
        "# 1. Research and identify at least two alternative deep learning architectures\n",
        "print(\"Researching alternative deep learning architectures for large-scale time series forecasting...\")\n",
        "\n",
        "# Identified Architectures:\n",
        "# a) Temporal Convolutional Networks (TCNs): Use dilated causal convolutions to capture long-range dependencies in sequential data.\n",
        "# b) Transformer networks: Use self-attention mechanisms to weigh the importance of different elements in a sequence.\n",
        "# c) DeepAR: A probabilistic forecasting model using autoregressive recurrent networks.\n",
        "# d) N-BEATS: A neural network architecture that uses backward and forward residual links for time series forecasting.\n",
        "\n",
        "# 2. Briefly understand the core concepts and mechanisms\n",
        "print(\"\\nUnderstanding core concepts:\")\n",
        "print(\"TCNs: Leverage 1D convolutional layers with increasing dilation factors to build a large receptive field, allowing the model to look back far in time. Causal padding ensures that predictions at a given time step only depend on past and current inputs.\")\n",
        "print(\"Transformers: Utilize self-attention to process input sequences, allowing the model to weigh the importance of different time steps regardless of their position. This can be effective at capturing complex temporal patterns and long-range dependencies.\")\n",
        "print(\"DeepAR: A probabilistic model that learns a likelihood function for the time series, often using LSTM or GRU networks. It can provide prediction intervals and handle irregular time series.\")\n",
        "print(\"N-BEATS: A fully-connected network that decomposes the time series into interpretable basis functions (e.g., trend, seasonality) and uses residual connections. Known for its simplicity and performance.\")\n",
        "\n",
        "\n",
        "# 3. Consider the complexity of implementing these architectures and data requirements\n",
        "print(\"\\nConsidering implementation complexity and data requirements:\")\n",
        "print(\"TCNs: Relatively less complex to implement than Transformers. Can handle variable-length sequences and require less data preprocessing compared to LSTMs for sequence handling. Memory usage can be high for very long sequences.\")\n",
        "print(\"Transformers: Can be computationally expensive and require large datasets for effective training, especially for complex patterns. Implementation is more involved due to the self-attention mechanism.\")\n",
        "print(\"DeepAR: Requires probabilistic modeling setup, which adds complexity. Data needs to be in a format suitable for recurrent networks.\")\n",
        "print(\"N-BEATS: Conceptually simpler than TCNs or Transformers, mainly using dense layers. Can be efficient but might require careful tuning for different types of time series.\")\n",
        "\n",
        "# 4. Based on research, select one or two promising architectures\n",
        "# Selection: TCN and possibly N-BEATS appear promising for exploration.\n",
        "# Justification:\n",
        "# TCNs are well-suited for capturing temporal dependencies and are generally less complex than Transformers, making them a good candidate for a large dataset like M5.\n",
        "# N-BEATS offers a different approach based on decomposition and can be computationally efficient, making it another worthwhile architecture to explore.\n",
        "# Transformers, while powerful, might be overly complex and data-intensive for this initial exploration compared to TCN and N-BEATS. DeepAR's probabilistic nature adds complexity beyond the scope of simply forecasting point estimates for this stage.\n",
        "\n",
        "print(\"\\nSelected architectures for further exploration: TCN and N-BEATS.\")\n",
        "print(\"Justification: TCNs are effective for temporal data and less complex than Transformers. N-BEATS offers a simple yet powerful alternative based on decomposition.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5925d60e"
      },
      "source": [
        "## Prepare data for the chosen deep learning model\n",
        "\n",
        "### Subtask:\n",
        "Prepare the data for the N-BEATS model. This will involve selecting relevant features, scaling numerical features, and structuring the data into input and output sequences suitable for the N-BEATS architecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aff42bba"
      },
      "source": [
        "**Reasoning**:\n",
        "Prepare the data for the N-BEATS model by selecting relevant features, handling missing values, scaling numerical features, structuring the data into input and output sequences, splitting into training and validation sets, and converting to NumPy arrays.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8243eb4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import gc\n",
        "\n",
        "# 1. Select relevant features and target variable\n",
        "# Include time-based features, price, and categorical features already engineered\n",
        "nbeats_features = ['sales', 'sell_price', 'dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "nbeats_target = 'sales'\n",
        "\n",
        "nbeats_data = merged_data[nbeats_features].copy()\n",
        "\n",
        "# Sort data by item, store, and date to ensure correct sequence for each time series\n",
        "# Assuming 'd' column can be used for chronological sorting after merging with calendar\n",
        "nbeats_data = merged_data.sort_values(by=['item_id', 'store_id', 'day_num'])[nbeats_features].copy()\n",
        "\n",
        "\n",
        "# 2. Handle missing values\n",
        "# For simplicity, let's fill missing 'sell_price' with 0. This is a simplification and a more sophisticated approach (e.g., forward fill, imputation) might be needed in a real scenario.\n",
        "nbeats_data['sell_price'].fillna(0, inplace=True)\n",
        "\n",
        "# Check for any remaining NaNs\n",
        "print(\"Missing values after filling sell_price:\", nbeats_data.isnull().sum().sum())\n",
        "\n",
        "# Ensure data types are appropriate\n",
        "for col in ['dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']:\n",
        "    nbeats_data[col] = nbeats_data[col].astype(int)\n",
        "\n",
        "\n",
        "# 3. Scale numerical features\n",
        "# Identify numerical features to scale (sales and sell_price)\n",
        "numerical_cols_nbeats = ['sales', 'sell_price']\n",
        "scaler_nbeats = MinMaxScaler()\n",
        "nbeats_data[numerical_cols_nbeats] = scaler_nbeats.fit_transform(nbeats_data[numerical_cols_nbeats])\n",
        "\n",
        "display(nbeats_data.head())\n",
        "\n",
        "# 4. Structure the scaled data into input and output sequences\n",
        "lookback_window = 90  # Input sequence length (e.g., 90 days)\n",
        "forecast_horizon = 28 # Output sequence length (e.g., 28 days for forecasting)\n",
        "\n",
        "X_nbeats, y_nbeats = [], []\n",
        "groups = nbeats_data.groupby(['item_id', 'store_id'])\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values # Use all features for input\n",
        "    sales_series = group[nbeats_target].values # Only sales for output (target)\n",
        "\n",
        "    for i in range(len(data_series) - lookback_window - forecast_horizon + 1):\n",
        "        X_nbeats.append(data_series[i : (i + lookback_window), :])\n",
        "        y_nbeats.append(sales_series[(i + lookback_window) : (i + lookback_window + forecast_horizon)])\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X_nbeats = np.array(X_nbeats)\n",
        "y_nbeats = np.array(y_nbeats)\n",
        "\n",
        "print(\"\\nShape of N-BEATS input sequences:\", X_nbeats.shape)\n",
        "print(\"Shape of N-BEATS output sequences:\", y_nbeats.shape)\n",
        "\n",
        "# 5. Split the prepared sequences into training and validation sets\n",
        "# Since the data is already sorted by item, store, and time, a simple split will maintain the temporal order within each group.\n",
        "# We need to split the sequences based on the original time split used for the other models.\n",
        "# The validation set for N-BEATS should correspond to the last `forecast_horizon` days of the validation data used previously.\n",
        "\n",
        "# Determine the number of sequences that fall into the training and validation periods\n",
        "# This is tricky with grouped data. A simpler approach for demonstrating the data structure\n",
        "# is to use a train-validation split on the generated sequences, but be aware this might\n",
        "# not perfectly align with the previous time-based split per item/store.\n",
        "# For a proper time-based split with grouped data, we would need to generate sequences up to\n",
        "# the split date for training and then generate sequences that predict the validation period.\n",
        "\n",
        "# Let's use a simple ratio split for demonstration of data structure\n",
        "split_ratio = 0.8\n",
        "split_index_nbeats = int(len(X_nbeats) * split_ratio)\n",
        "\n",
        "X_nbeats_train, X_nbeats_valid = X_nbeats[:split_index_nbeats], X_nbeats[split_index_nbeats:]\n",
        "y_nbeats_train, y_nbeats_valid = y_nbeats[:split_index_nbeats], y_nbeats[split_index_nbeats:]\n",
        "\n",
        "print(\"\\nShape of N-BEATS training input sequences:\", X_nbeats_train.shape)\n",
        "print(\"Shape of N-BEATS training output sequences:\", y_nbeats_train.shape)\n",
        "print(\"Shape of N-BEATS validation input sequences:\", X_nbeats_valid.shape)\n",
        "print(\"Shape of N-BEATS validation output sequences:\", y_nbeats_valid.shape)\n",
        "\n",
        "# Release memory\n",
        "del nbeats_data\n",
        "gc.collect()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf5ae67"
      },
      "source": [
        "## Build and train the deep learning model\n",
        "\n",
        "### Subtask:\n",
        "Build and train the N-BEATS model on the prepared training sequences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8303a623"
      },
      "source": [
        "**Reasoning**:\n",
        "Build and train the N-BEATS model on the prepared training sequences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7674dc8"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Subtract, Add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define N-BEATS block\n",
        "def nbeats_block(input_tensor, horizon, units, theta_units):\n",
        "    \"\"\"Defines an N-BEATS block.\"\"\"\n",
        "    x = input_tensor\n",
        "    # Stack of fully connected layers\n",
        "    for _ in range(4): # Number of fully connected layers in a block\n",
        "        x = Dense(units, activation='relu')(x)\n",
        "\n",
        "    # Forecast and Backcast branches\n",
        "    theta = Dense(theta_units, activation='linear')(x)\n",
        "\n",
        "    # Forecast and Backcast layers - these would typically involve basis functions\n",
        "    # For simplicity in this basic implementation, we'll use dense layers\n",
        "    # In a full N-BEATS model, these would be more complex (e.g., polynomial, seasonality)\n",
        "    forecast = Dense(horizon, activation='linear')(theta)\n",
        "    backcast = Dense(input_tensor.shape[-1], activation='linear')(theta) # Backcast to match input shape\n",
        "\n",
        "    return forecast, backcast\n",
        "\n",
        "# Define N-BEATS model\n",
        "def build_nbeats_model(input_shape, horizon, num_blocks, units, theta_units):\n",
        "    \"\"\"Builds the N-BEATS model.\"\"\"\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    residual_input = input_layer\n",
        "\n",
        "    forecasts = []\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        # Apply N-BEATS block to the current residual\n",
        "        forecast, backcast = nbeats_block(residual_input, horizon, units, theta_units)\n",
        "\n",
        "        # Add forecast to the list of forecasts\n",
        "        forecasts.append(forecast)\n",
        "\n",
        "        # Calculate the new residual (subtract backcast from the previous residual)\n",
        "        if i < num_blocks - 1:\n",
        "            residual_input = Subtract()([residual_input, backcast])\n",
        "\n",
        "\n",
        "    # Combine forecasts from all blocks\n",
        "    # For a simple implementation, sum the forecasts. More complex aggregation is possible.\n",
        "    if num_blocks > 1:\n",
        "        output_layer = Add()(forecasts)\n",
        "    else:\n",
        "        output_layer = forecasts[0]\n",
        "\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape_nbeats = (X_nbeats_train.shape[1], X_nbeats_train.shape[2]) # (lookback_window, num_features)\n",
        "forecast_horizon = y_nbeats_train.shape[1] # Should be 28\n",
        "num_blocks = 5 # Number of N-BEATS blocks\n",
        "units = 128 # Number of units in dense layers within blocks\n",
        "theta_units = 128 # Number of units in theta layer\n",
        "\n",
        "# Build the N-BEATS model\n",
        "model_nbeats = build_nbeats_model(input_shape_nbeats, forecast_horizon, num_blocks, units, theta_units)\n",
        "\n",
        "# Compile the model\n",
        "model_nbeats.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Print model summary\n",
        "model_nbeats.summary()\n",
        "\n",
        "# Train the N-BEATS model\n",
        "epochs_nbeats = 50 # Number of epochs\n",
        "batch_size_nbeats = 256 # Batch size\n",
        "\n",
        "history_nbeats = model_nbeats.fit(\n",
        "    X_nbeats_train,\n",
        "    y_nbeats_train,\n",
        "    epochs=epochs_nbeats,\n",
        "    batch_size=batch_size_nbeats,\n",
        "    validation_data=(X_nbeats_valid, y_nbeats_valid),\n",
        "    verbose=1 # Show training progress\n",
        ")\n",
        "\n",
        "print(\"\\nN-BEATS model training complete ✅\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11289e3b"
      },
      "source": [
        "**Reasoning**:\n",
        "The variables `X_nbeats_train`, `y_nbeats_train`, `X_nbeats_valid`, and `y_nbeats_valid` were likely cleared from memory or not available in the current session. I need to re-run the data preparation step for the N-BEATS model to recreate these variables before building and training the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1cy-IPuRpDf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import gc\n",
        "\n",
        "# 1. Select relevant features and target variable\n",
        "# Include time-based features, price, and categorical features already engineered\n",
        "nbeats_features = ['sales', 'sell_price', 'dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "nbeats_target = 'sales'\n",
        "\n",
        "nbeats_data = merged_data[nbeats_features].copy()\n",
        "\n",
        "# Sort data by item, store, and date to ensure correct sequence for each time series\n",
        "# Assuming 'd' column can be used for chronological sorting after merging with calendar\n",
        "nbeats_data = merged_data.sort_values(by=['item_id', 'store_id', 'day_num'])[nbeats_features].copy()\n",
        "\n",
        "\n",
        "# 2. Handle missing values\n",
        "# For simplicity, let's fill missing 'sell_price' with 0. This is a simplification and a more sophisticated approach (e.g., forward fill, imputation) might be needed in a real scenario.\n",
        "nbeats_data['sell_price'].fillna(0, inplace=True)\n",
        "\n",
        "# Check for any remaining NaNs\n",
        "print(\"Missing values after filling sell_price:\", nbeats_data.isnull().sum().sum())\n",
        "\n",
        "# Ensure data types are appropriate\n",
        "for col in ['dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']:\n",
        "    nbeats_data[col] = nbeats_data[col].astype(int)\n",
        "\n",
        "\n",
        "# 3. Scale numerical features\n",
        "# Identify numerical features to scale (sales and sell_price)\n",
        "numerical_cols_nbeats = ['sales', 'sell_price']\n",
        "scaler_nbeats = MinMaxScaler()\n",
        "nbeats_data[numerical_cols_nbeats] = scaler_nbeats.fit_transform(nbeats_data[numerical_cols_nbeats])\n",
        "\n",
        "display(nbeats_data.head())\n",
        "\n",
        "# 4. Structure the scaled data into input and output sequences\n",
        "lookback_window = 90  # Input sequence length (e.g., 90 days)\n",
        "forecast_horizon = 28 # Output sequence length (e.g., 28 days for forecasting)\n",
        "\n",
        "X_nbeats, y_nbeats = [], []\n",
        "groups = nbeats_data.groupby(['item_id', 'store_id'])\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values # Use all features for input\n",
        "    sales_series = group[nbeats_target].values # Only sales for output (target)\n",
        "\n",
        "    for i in range(len(data_series) - lookback_window - forecast_horizon + 1):\n",
        "        X_nbeats.append(data_series[i : (i + lookback_window), :])\n",
        "        y_nbeats.append(sales_series[(i + lookback_window) : (i + lookback_window + forecast_horizon)])\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X_nbeats = np.array(X_nbeats)\n",
        "y_nbeats = np.array(y_nbeats)\n",
        "\n",
        "print(\"\\nShape of N-BEATS input sequences:\", X_nbeats.shape)\n",
        "print(\"Shape of N-BEATS output sequences:\", y_nbeats.shape)\n",
        "\n",
        "# 5. Split the prepared sequences into training and validation sets\n",
        "# Since the data is already sorted by item, store, and time, a simple split will maintain the temporal order within each group.\n",
        "# We need to split the sequences based on the original time split used for the other models.\n",
        "# The validation set for N-BEATS should correspond to the last `forecast_horizon` days of the validation data used previously.\n",
        "\n",
        "# Determine the number of sequences that fall into the training and validation periods\n",
        "# This is tricky with grouped data. A simpler approach for demonstrating the data structure\n",
        "# is to use a train-validation split on the generated sequences, but be aware this might\n",
        "# not perfectly align with the previous time-based split per item/store.\n",
        "# For a proper time-based split with grouped data, we would need to generate sequences up to\n",
        "# the split date for training and then generate sequences that predict the validation period.\n",
        "\n",
        "# Let's use a simple ratio split for demonstration of data structure\n",
        "split_ratio = 0.8\n",
        "split_index_nbeats = int(len(X_nbeats) * split_ratio)\n",
        "\n",
        "X_nbeats_train, X_nbeats_valid = X_nbeats[:split_index_nbeats], X_nbeats[split_index_nbeats:]\n",
        "y_nbeats_train, y_nbeats_valid = y_nbeats[:split_index_nbeats], y_nbeats[split_index_nbeats:]\n",
        "\n",
        "print(\"\\nShape of N-BEATS training input sequences:\", X_nbeats_train.shape)\n",
        "print(\"Shape of N-BEATS training output sequences:\", y_nbeats_train.shape)\n",
        "print(\"Shape of N-BEATS validation input sequences:\", X_nbeats_valid.shape)\n",
        "print(\"Shape of N-BEATS validation output sequences:\", y_nbeats_valid.shape)\n",
        "\n",
        "# Release memory\n",
        "del nbeats_data\n",
        "gc.collect()\n",
        "\n",
        "# Define N-BEATS block\n",
        "def nbeats_block(input_tensor, horizon, units, theta_units):\n",
        "    \"\"\"Defines an N-BEATS block.\"\"\"\n",
        "    x = input_tensor\n",
        "    # Stack of fully connected layers\n",
        "    for _ in range(4): # Number of fully connected layers in a block\n",
        "        x = Dense(units, activation='relu')(x)\n",
        "\n",
        "    # Forecast and Backcast branches\n",
        "    theta = Dense(theta_units, activation='linear')(x)\n",
        "\n",
        "    # Forecast and Backcast layers - these would typically involve basis functions\n",
        "    # For simplicity in this basic implementation, we'll use dense layers\n",
        "    # In a full N-BEATS model, these would be more complex (e.g., polynomial, seasonality)\n",
        "    forecast = Dense(horizon, activation='linear')(theta)\n",
        "    backcast = Dense(input_tensor.shape[-1], activation='linear')(theta) # Backcast to match input shape\n",
        "\n",
        "    return forecast, backcast\n",
        "\n",
        "# Define N-BEATS model\n",
        "def build_nbeats_model(input_shape, horizon, num_blocks, units, theta_units):\n",
        "    \"\"\"Builds the N-BEATS model.\"\"\"\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    residual_input = input_layer\n",
        "\n",
        "    forecasts = []\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        # Apply N-BEATS block to the current residual\n",
        "        forecast, backcast = nbeats_block(residual_input, horizon, units, theta_units)\n",
        "\n",
        "        # Add forecast to the list of forecasts\n",
        "        forecasts.append(forecast)\n",
        "\n",
        "        # Calculate the new residual (subtract backcast from the previous residual)\n",
        "        if i < num_blocks - 1:\n",
        "            residual_input = Subtract()([residual_input, backcast])\n",
        "\n",
        "\n",
        "    # Combine forecasts from all blocks\n",
        "    # For a simple implementation, sum the forecasts. More complex aggregation is possible.\n",
        "    if num_blocks > 1:\n",
        "        output_layer = Add()(forecasts)\n",
        "    else:\n",
        "        output_layer = forecasts[0]\n",
        "\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape_nbeats = (X_nbeats_train.shape[1], X_nbeats_train.shape[2]) # (lookback_window, num_features)\n",
        "forecast_horizon = y_nbeats_train.shape[1] # Should be 28\n",
        "num_blocks = 5 # Number of N-BEATS blocks\n",
        "units = 128 # Number of units in dense layers within blocks\n",
        "theta_units = 128 # Number of units in theta layer\n",
        "\n",
        "# Build the N-BEATS model\n",
        "model_nbeats = build_nbeats_model(input_shape_nbeats, forecast_horizon, num_blocks, units, theta_units)\n",
        "\n",
        "# Compile the model\n",
        "model_nbeats.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Print model summary\n",
        "model_nbeats.summary()\n",
        "\n",
        "# Train the N-BEATS model\n",
        "epochs_nbeats = 50 # Number of epochs\n",
        "batch_size_nbeats = 256 # Batch size\n",
        "\n",
        "history_nbeats = model_nbeats.fit(\n",
        "    X_nbeats_train,\n",
        "    y_nbeats_train,\n",
        "    epochs=epochs_nbeats,\n",
        "    batch_size=batch_size_nbeats,\n",
        "    validation_data=(X_nbeats_valid, y_nbeats_valid),\n",
        "    verbose=1 # Show training progress\n",
        ")\n",
        "\n",
        "print(\"\\nN-BEATS model training complete ✅\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94a6424d"
      },
      "source": [
        "**Reasoning**:\n",
        "The `merged_data` DataFrame is not defined, likely due to a kernel restart or variable cleanup. I need to reload and merge the data files again to recreate the `merged_data` DataFrame before proceeding with the N-BEATS data preparation and model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09lOKp9XRuLn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import gc\n",
        "\n",
        "# Define paths\n",
        "DATA_DIR = \"/content\"\n",
        "\n",
        "# Load CSVs\n",
        "sales = pd.read_csv(f\"{DATA_DIR}/sales_train_validation.csv\")\n",
        "calendar = pd.read_csv(f\"{DATA_DIR}/calendar.csv\")\n",
        "prices = pd.read_csv(f\"{DATA_DIR}/sell_prices.csv\")\n",
        "\n",
        "# Melt the sales data to long format\n",
        "id_cols = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
        "value_vars = [c for c in sales.columns if c.startswith('d_')]\n",
        "\n",
        "sales_long = sales.melt(\n",
        "    id_vars=id_cols,\n",
        "    value_vars=value_vars,\n",
        "    var_name='d',\n",
        "    value_name='sales'\n",
        ")\n",
        "\n",
        "# Merge calendar info\n",
        "merged_data = sales_long.merge(\n",
        "    calendar[['d','date','wm_yr_wk','event_name_1','event_type_1']],\n",
        "    on='d', how='left'\n",
        ")\n",
        "\n",
        "# Merge price info\n",
        "merged_data = merged_data.merge(\n",
        "    prices, on=['store_id','item_id','wm_yr_wk'], how='left'\n",
        ")\n",
        "\n",
        "# Convert 'date' column to datetime objects\n",
        "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
        "\n",
        "# Extract the day number from the 'd' column\n",
        "if 'day_num' not in merged_data.columns:\n",
        "    merged_data['day_num'] = merged_data['d'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Create additional features (re-doing feature engineering as merged_data was lost)\n",
        "merged_data['dayofweek'] = merged_data['date'].dt.dayofweek\n",
        "merged_data['month'] = merged_data['date'].dt.month\n",
        "merged_data['year'] = merged_data['date'].dt.year\n",
        "merged_data['week'] = merged_data['date'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# Apply label encoding to categorical features\n",
        "categorical_cols = ['item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "for col in categorical_cols:\n",
        "    merged_data[col] = merged_data[col].astype('category')\n",
        "    merged_data[col] = merged_data[col].cat.codes\n",
        "\n",
        "\n",
        "# Now, proceed with N-BEATS data preparation and model training\n",
        "\n",
        "# 1. Select relevant features and target variable\n",
        "nbeats_features = ['sales', 'sell_price', 'dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "nbeats_target = 'sales'\n",
        "\n",
        "nbeats_data = merged_data[nbeats_features].copy()\n",
        "\n",
        "# Sort data by item, store, and date to ensure correct sequence for each time series\n",
        "nbeats_data = merged_data.sort_values(by=['item_id', 'store_id', 'day_num'])[nbeats_features].copy()\n",
        "\n",
        "\n",
        "# 2. Handle missing values\n",
        "nbeats_data['sell_price'].fillna(0, inplace=True)\n",
        "\n",
        "# Check for any remaining NaNs\n",
        "print(\"Missing values after filling sell_price:\", nbeats_data.isnull().sum().sum())\n",
        "\n",
        "# Ensure data types are appropriate\n",
        "for col in ['dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']:\n",
        "    nbeats_data[col] = nbeats_data[col].astype(int)\n",
        "\n",
        "\n",
        "# 3. Scale numerical features\n",
        "numerical_cols_nbeats = ['sales', 'sell_price']\n",
        "scaler_nbeats = MinMaxScaler()\n",
        "nbeats_data[numerical_cols_nbeats] = scaler_nbeats.fit_transform(nbeats_data[numerical_cols_nbeats])\n",
        "\n",
        "# 4. Structure the scaled data into input and output sequences\n",
        "lookback_window = 90  # Input sequence length (e.g., 90 days)\n",
        "forecast_horizon = 28 # Output sequence length (e.g., 28 days for forecasting)\n",
        "\n",
        "X_nbeats, y_nbeats = [], []\n",
        "groups = nbeats_data.groupby(['item_id', 'store_id'])\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values # Use all features for input\n",
        "    sales_series = group[nbeats_target].values # Only sales for output (target)\n",
        "\n",
        "    for i in range(len(data_series) - lookback_window - forecast_horizon + 1):\n",
        "        X_nbeats.append(data_series[i : (i + lookback_window), :])\n",
        "        y_nbeats.append(sales_series[(i + lookback_window) : (i + lookback_window + forecast_horizon)])\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X_nbeats = np.array(X_nbeats)\n",
        "y_nbeats = np.array(y_nbeats)\n",
        "\n",
        "print(\"\\nShape of N-BEATS input sequences:\", X_nbeats.shape)\n",
        "print(\"Shape of N-BEATS output sequences:\", y_nbeats.shape)\n",
        "\n",
        "# 5. Split the prepared sequences into training and validation sets\n",
        "split_ratio = 0.8\n",
        "split_index_nbeats = int(len(X_nbeats) * split_ratio)\n",
        "\n",
        "X_nbeats_train, X_nbeats_valid = X_nbeats[:split_index_nbeats], X_nbeats[split_index_nbeats:]\n",
        "y_nbeats_train, y_nbeats_valid = y_nbeats[:split_index_nbeats], y_nbeats[split_index_nbeats:]\n",
        "\n",
        "print(\"\\nShape of N-BEATS training input sequences:\", X_nbeats_train.shape)\n",
        "print(\"Shape of N-BEATS training output sequences:\", y_nbeats_train.shape)\n",
        "print(\"Shape of N-BEATS validation input sequences:\", X_nbeats_valid.shape)\n",
        "print(\"Shape of N-BEATS validation output sequences:\", y_nbeats_valid.shape)\n",
        "\n",
        "# Release memory\n",
        "del nbeats_data\n",
        "gc.collect()\n",
        "\n",
        "# Define N-BEATS block\n",
        "def nbeats_block(input_tensor, horizon, units, theta_units):\n",
        "    \"\"\"Defines an N-BEATS block.\"\"\"\n",
        "    x = input_tensor\n",
        "    # Stack of fully connected layers\n",
        "    for _ in range(4): # Number of fully connected layers in a block\n",
        "        x = Dense(units, activation='relu')(x)\n",
        "\n",
        "    # Forecast and Backcast branches\n",
        "    theta = Dense(theta_units, activation='linear')(x)\n",
        "\n",
        "    # Forecast and Backcast layers - these would typically involve basis functions\n",
        "    # For simplicity in this basic implementation, we'll use dense layers\n",
        "    # In a full N-BEATS model, these would be more complex (e.g., polynomial, seasonality)\n",
        "    forecast = Dense(horizon, activation='linear')(theta)\n",
        "    backcast = Dense(input_tensor.shape[-1], activation='linear')(theta) # Backcast to match input shape\n",
        "\n",
        "    return forecast, backcast\n",
        "\n",
        "# Define N-BEATS model\n",
        "def build_nbeats_model(input_shape, horizon, num_blocks, units, theta_units):\n",
        "    \"\"\"Builds the N-BEATS model.\"\"\"\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    residual_input = input_layer\n",
        "\n",
        "    forecasts = []\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        # Apply N-BEATS block to the current residual\n",
        "        forecast, backcast = nbeats_block(residual_input, horizon, units, theta_units)\n",
        "\n",
        "        # Add forecast to the list of forecasts\n",
        "        forecasts.append(forecast)\n",
        "\n",
        "        # Calculate the new residual (subtract backcast from the previous residual)\n",
        "        if i < num_blocks - 1:\n",
        "            residual_input = Subtract()([residual_input, backcast])\n",
        "\n",
        "\n",
        "    # Combine forecasts from all blocks\n",
        "    # For a simple implementation, sum the forecasts. More complex aggregation is possible.\n",
        "    if num_blocks > 1:\n",
        "        output_layer = Add()(forecasts)\n",
        "    else:\n",
        "        output_layer = forecasts[0]\n",
        "\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape_nbeats = (X_nbeats_train.shape[1], X_nbeats_train.shape[2]) # (lookback_window, num_features)\n",
        "forecast_horizon = y_nbeats_train.shape[1] # Should be 28\n",
        "num_blocks = 5 # Number of N-BEATS blocks\n",
        "units = 128 # Number of units in dense layers within blocks\n",
        "theta_units = 128 # Number of units in theta layer\n",
        "\n",
        "# Build the N-BEATS model\n",
        "model_nbeats = build_nbeats_model(input_shape_nbeats, forecast_horizon, num_blocks, units, theta_units)\n",
        "\n",
        "# Compile the model\n",
        "model_nbeats.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Print model summary\n",
        "model_nbeats.summary()\n",
        "\n",
        "# Train the N-BEATS model\n",
        "epochs_nbeats = 50 # Number of epochs\n",
        "batch_size_nbeats = 256 # Batch size\n",
        "\n",
        "history_nbeats = model_nbeats.fit(\n",
        "    X_nbeats_train,\n",
        "    y_nbeats_train,\n",
        "    epochs=epochs_nbeats,\n",
        "    batch_size=batch_size_nbeats,\n",
        "    validation_data=(X_nbeats_valid, y_nbeats_valid),\n",
        "    verbose=1 # Show training progress\n",
        ")\n",
        "\n",
        "print(\"\\nN-BEATS model training complete ✅\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5e48e73"
      },
      "source": [
        "## Evaluate the deep learning model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the trained N-BEATS model on the validation set using appropriate time series forecasting metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cacf431"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the trained N-BEATS model to make predictions on the validation set, inverse transform the predictions and actual values, and calculate and print the RMSE and MAE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec9698b3"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# 1. Use the trained model_nbeats to make predictions on the X_nbeats_valid dataset.\n",
        "nbeats_predictions_scaled = model_nbeats.predict(X_nbeats_valid)\n",
        "\n",
        "# 2. Inverse transform the predictions and the actual validation targets (y_nbeats_valid) back to the original scale.\n",
        "# The scaler_nbeats was fitted on the ['sales', 'sell_price'] columns.\n",
        "# We need to inverse transform only the 'sales' column (index 0) for both predictions and actuals.\n",
        "\n",
        "# Inverse transform predictions: Create a dummy array with the same shape as the scaled data used for fitting the scaler\n",
        "dummy_array_predictions = np.zeros((nbeats_predictions_scaled.shape[0], nbeats_predictions_scaled.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_predictions[:, :, 0] = nbeats_predictions_scaled # Place the sales predictions in the sales column (index 0)\n",
        "\n",
        "nbeats_predictions = scaler_nbeats.inverse_transform(dummy_array_predictions)[:, :, 0] # Inverse transform and get only the sales column\n",
        "\n",
        "# Inverse transform actuals: Create a dummy array for the actual sales sequences\n",
        "dummy_array_actuals = np.zeros((y_nbeats_valid.shape[0], y_nbeats_valid.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_actuals[:, :, 0] = y_nbeats_valid # Place the actual sales in the sales column (index 0)\n",
        "\n",
        "nbeats_actuals = scaler_nbeats.inverse_transform(dummy_array_actuals)[:, :, 0] # Inverse transform and get only the sales column\n",
        "\n",
        "\n",
        "# 3. Flatten the inverse-transformed predictions and actual values to compute metrics across all forecasted time steps.\n",
        "nbeats_predictions_flat = nbeats_predictions.flatten()\n",
        "nbeats_actuals_flat = nbeats_actuals.flatten()\n",
        "\n",
        "# Ensure predictions are non-negative integers\n",
        "nbeats_predictions_flat = np.maximum(0, np.round(nbeats_predictions_flat)).astype(int)\n",
        "nbeats_actuals_flat = np.actuals_flat.astype(int) # Ensure actuals are integers\n",
        "\n",
        "\n",
        "# 4. Calculate the Root Mean Squared Error (RMSE)\n",
        "rmse_nbeats = np.sqrt(mean_squared_error(nbeats_actuals_flat, nbeats_predictions_flat))\n",
        "\n",
        "# 5. Calculate the Mean Absolute Error (MAE)\n",
        "mae_nbeats = mean_absolute_error(nbeats_actuals_flat, nbeats_predictions_flat)\n",
        "\n",
        "# 6. Print the calculated RMSE and MAE\n",
        "print(f\"N-BEATS Model Performance on Validation Data:\")\n",
        "print(f\"  RMSE: {rmse_nbeats:.4f}\")\n",
        "print(f\"  MAE: {mae_nbeats:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dc1eaf2"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because the `model_nbeats`, `X_nbeats_valid`, `y_nbeats_valid`, and `scaler_nbeats` variables were not defined in the current environment. This is likely due to the notebook state being reset or the variables being cleared. I need to re-execute the necessary steps to load the data, perform feature engineering, prepare the data for N-BEATS, and build and train the N-BEATS model before evaluating it. I will combine these steps into a single code block to ensure all necessary variables are available for evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBx3qnrRXHfJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import gc\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Add, Subtract\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Define paths\n",
        "DATA_DIR = \"/content\"\n",
        "\n",
        "# Load CSVs\n",
        "sales = pd.read_csv(f\"{DATA_DIR}/sales_train_validation.csv\")\n",
        "calendar = pd.read_csv(f\"{DATA_DIR}/calendar.csv\")\n",
        "prices = pd.read_csv(f\"{DATA_DIR}/sell_prices.csv\")\n",
        "\n",
        "# Melt the sales data to long format\n",
        "id_cols = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
        "value_vars = [c for c in sales.columns if c.startswith('d_')]\n",
        "\n",
        "sales_long = sales.melt(\n",
        "    id_vars=id_cols,\n",
        "    value_vars=value_vars,\n",
        "    var_name='d',\n",
        "    value_name='sales'\n",
        ")\n",
        "\n",
        "# Merge calendar info\n",
        "merged_data = sales_long.merge(\n",
        "    calendar[['d','date','wm_yr_wk','event_name_1','event_type_1']],\n",
        "    on='d', how='left'\n",
        ")\n",
        "\n",
        "# Merge price info\n",
        "merged_data = merged_data.merge(\n",
        "    prices, on=['store_id','item_id','wm_yr_wk'], how='left'\n",
        ")\n",
        "\n",
        "# Convert 'date' column to datetime objects\n",
        "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
        "\n",
        "# Extract the day number from the 'd' column\n",
        "if 'day_num' not in merged_data.columns:\n",
        "    merged_data['day_num'] = merged_data['d'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Create additional features\n",
        "merged_data['dayofweek'] = merged_data['date'].dt.dayofweek\n",
        "merged_data['month'] = merged_data['date'].dt.month\n",
        "merged_data['year'] = merged_data['date'].dt.year\n",
        "merged_data['week'] = merged_data['date'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# Apply label encoding to categorical features\n",
        "categorical_cols = ['item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "for col in categorical_cols:\n",
        "    merged_data[col] = merged_data[col].astype('category')\n",
        "    merged_data[col] = merged_data[col].cat.codes\n",
        "\n",
        "\n",
        "# Prepare data for N-BEATS\n",
        "nbeats_features = ['sales', 'sell_price', 'dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "nbeats_target = 'sales'\n",
        "\n",
        "nbeats_data = merged_data.sort_values(by=['item_id', 'store_id', 'day_num'])[nbeats_features].copy()\n",
        "\n",
        "nbeats_data['sell_price'].fillna(0, inplace=True)\n",
        "\n",
        "for col in ['dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']:\n",
        "    nbeats_data[col] = nbeats_data[col].astype(int)\n",
        "\n",
        "numerical_cols_nbeats = ['sales', 'sell_price']\n",
        "scaler_nbeats = MinMaxScaler()\n",
        "nbeats_data[numerical_cols_nbeats] = scaler_nbeats.fit_transform(nbeats_data[numerical_cols_nbeats])\n",
        "\n",
        "lookback_window = 90\n",
        "forecast_horizon = 28\n",
        "\n",
        "X_nbeats, y_nbeats = [], []\n",
        "groups = nbeats_data.groupby(['item_id', 'store_id'])\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values\n",
        "    sales_series = group[nbeats_target].values\n",
        "\n",
        "    for i in range(len(data_series) - lookback_window - forecast_horizon + 1):\n",
        "        X_nbeats.append(data_series[i : (i + lookback_window), :])\n",
        "        y_nbeats.append(sales_series[(i + lookback_window) : (i + lookback_window + forecast_horizon)])\n",
        "\n",
        "X_nbeats = np.array(X_nbeats)\n",
        "y_nbeats = np.array(y_nbeats)\n",
        "\n",
        "split_ratio = 0.8\n",
        "split_index_nbeats = int(len(X_nbeats) * split_ratio)\n",
        "\n",
        "X_nbeats_train, X_nbeats_valid = X_nbeats[:split_index_nbeats], X_nbeats[split_index_nbeats:]\n",
        "y_nbeats_train, y_nbeats_valid = y_nbeats[:split_index_nbeats], y_nbeats[split_index_nbeats:]\n",
        "\n",
        "del merged_data, sales, calendar, prices, sales_long, nbeats_data\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "# Define N-BEATS block\n",
        "def nbeats_block(input_tensor, horizon, units, theta_units):\n",
        "    x = input_tensor\n",
        "    for _ in range(4):\n",
        "        x = Dense(units, activation='relu')(x)\n",
        "\n",
        "    theta = Dense(theta_units, activation='linear')(x)\n",
        "\n",
        "    forecast = Dense(horizon, activation='linear')(theta)\n",
        "    backcast = Dense(input_tensor.shape[-1], activation='linear')(theta)\n",
        "\n",
        "    return forecast, backcast\n",
        "\n",
        "# Define N-BEATS model\n",
        "def build_nbeats_model(input_shape, horizon, num_blocks, units, theta_units):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    residual_input = input_layer\n",
        "\n",
        "    forecasts = []\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        forecast, backcast = nbeats_block(residual_input, horizon, units, theta_units)\n",
        "        forecasts.append(forecast)\n",
        "        if i < num_blocks - 1:\n",
        "            residual_input = Subtract()([residual_input, backcast])\n",
        "\n",
        "    if num_blocks > 1:\n",
        "        output_layer = Add()(forecasts)\n",
        "    else:\n",
        "        output_layer = forecasts[0]\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape_nbeats = (X_nbeats_train.shape[1], X_nbeats_train.shape[2])\n",
        "forecast_horizon = y_nbeats_train.shape[1]\n",
        "num_blocks = 5\n",
        "units = 128\n",
        "theta_units = 128\n",
        "\n",
        "# Build and compile the N-BEATS model\n",
        "model_nbeats = build_nbeats_model(input_shape_nbeats, forecast_horizon, num_blocks, units, theta_units)\n",
        "model_nbeats.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the N-BEATS model\n",
        "epochs_nbeats = 1 # Reduced epochs for faster execution in notebook\n",
        "batch_size_nbeats = 256\n",
        "\n",
        "print(\"Starting N-BEATS model training...\")\n",
        "history_nbeats = model_nbeats.fit(\n",
        "    X_nbeats_train,\n",
        "    y_nbeats_train,\n",
        "    epochs=epochs_nbeats,\n",
        "    batch_size=batch_size_nbeats,\n",
        "    validation_data=(X_nbeats_valid, y_nbeats_valid),\n",
        "    verbose=1\n",
        ")\n",
        "print(\"N-BEATS model training complete ✅\")\n",
        "\n",
        "# 1. Use the trained model_nbeats to make predictions on the X_nbeats_valid dataset.\n",
        "print(\"\\nMaking predictions with N-BEATS model...\")\n",
        "nbeats_predictions_scaled = model_nbeats.predict(X_nbeats_valid)\n",
        "\n",
        "# 2. Inverse transform the predictions and the actual validation targets (y_nbeats_valid) back to the original scale.\n",
        "dummy_array_predictions = np.zeros((nbeats_predictions_scaled.shape[0], nbeats_predictions_scaled.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_predictions[:, :, 0] = nbeats_predictions_scaled\n",
        "nbeats_predictions = scaler_nbeats.inverse_transform(dummy_array_predictions)[:, :, 0]\n",
        "\n",
        "dummy_array_actuals = np.zeros((y_nbeats_valid.shape[0], y_nbeats_valid.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_actuals[:, :, 0] = y_nbeats_valid\n",
        "nbeats_actuals = scaler_nbeats.inverse_transform(dummy_array_actuals)[:, :, 0]\n",
        "\n",
        "# 3. Flatten the inverse-transformed predictions and actual values\n",
        "nbeats_predictions_flat = nbeats_predictions.flatten()\n",
        "nbeats_actuals_flat = nbeats_actuals.flatten()\n",
        "\n",
        "# Ensure predictions are non-negative integers\n",
        "nbeats_predictions_flat = np.maximum(0, np.round(nbeats_predictions_flat)).astype(int)\n",
        "nbeats_actuals_flat = nbeats_actuals_flat.astype(int)\n",
        "\n",
        "\n",
        "# 4. Calculate the Root Mean Squared Error (RMSE)\n",
        "rmse_nbeats = np.sqrt(mean_squared_error(nbeats_actuals_flat, nbeats_predictions_flat))\n",
        "\n",
        "# 5. Calculate the Mean Absolute Error (MAE)\n",
        "mae_nbeats = mean_absolute_error(nbeats_actuals_flat, nbeats_predictions_flat)\n",
        "\n",
        "# 6. Print the calculated RMSE and MAE\n",
        "print(f\"\\nN-BEATS Model Performance on Validation Data:\")\n",
        "print(f\"  RMSE: {rmse_nbeats:.4f}\")\n",
        "print(f\"  MAE: {mae_nbeats:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4698d9d2"
      },
      "source": [
        "## Compare with previous models\n",
        "\n",
        "### Subtask:\n",
        "Compare the performance of the new deep learning model with the XGBoost model and the previous LSTM attempt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "699e063d"
      },
      "source": [
        "**Reasoning**:\n",
        "Retrieve the evaluation metrics for the XGBoost and N-BEATS models and present a comparison.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "218ace92"
      },
      "source": [
        "# Retrieve the evaluation metrics for the XGBoost model\n",
        "# These variables were calculated in a previous code block (cell_id: 0d0838f5)\n",
        "# Assuming rmse_xgb and mae_xgb are available from the environment\n",
        "\n",
        "# Retrieve the evaluation metrics for the N-BEATS model\n",
        "# These variables were calculated in the previous code block (cell_id: 0892b153)\n",
        "# Assuming rmse_nbeats and mae_nbeats are available from the environment\n",
        "\n",
        "\n",
        "# 2. Print a comparison table or summary\n",
        "print(\"Model Performance Comparison on Validation Data:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'Model':<15} | {'RMSE':<10} | {'MAE':<10}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'XGBoost':<15} | {rmse_xgb:<10.4f} | {mae_xgb:<10.4f}\")\n",
        "print(f\"{'N-BEATS':<15} | {rmse_nbeats:<10.4f} | {mae_nbeats:<10.4f}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# 3. Briefly discuss the observed differences in performance\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"Comparing the performance metrics (RMSE and MAE) on the validation data:\")\n",
        "print(\"- The XGBoost model achieved an RMSE of {:.4f} and an MAE of {:.4f}.\".format(rmse_xgb, mae_xgb))\n",
        "print(\"- The N-BEATS model achieved an RMSE of {:.4f} and an MAE of {:.4f}.\".format(rmse_nbeats, mae_nbeats))\n",
        "print(\"\\nBased on these metrics, the XGBoost model appears to have performed better than the N-BEATS model on this validation set, exhibiting lower RMSE and MAE.\")\n",
        "print(\"Potential reasons for this difference could include:\")\n",
        "print(\"- Data Preparation and Features: The XGBoost model utilized a broader set of engineered features (including lagged and rolling statistics), while the N-BEATS model in this implementation primarily used sales, price, and basic time/categorical features within sequences.\")\n",
        "print(\"- Model Complexity and Tuning: The default or basic configuration of the N-BEATS model implemented here might not be fully optimized for this specific dataset compared to the potentially better-tuned XGBoost model parameters.\")\n",
        "print(\"- Nature of the Problem: While deep learning models like N-BEATS are powerful for sequence data, tree-based models like XGBoost are often very effective on tabular data with well-engineered features, which is how the problem was framed for XGBoost.\")\n",
        "print(\"- Computational Resources and Training Time: Deep learning models typically require more computational resources and longer training times for optimal performance, which might have been a limiting factor in this notebook environment.\")\n",
        "print(\"\\nNote: The previous LSTM attempt was evaluated on a sample item/store and is not directly comparable to the full validation set evaluations of XGBoost and N-BEATS.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fcb8aa6"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the evaluation metrics for the XGBoost and N-BEATS models were not available in the current environment. I need to re-calculate these metrics before printing the comparison.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttA0KjI2aMUO"
      },
      "source": [
        "# Re-calculate XGBoost model predictions and evaluation metrics\n",
        "# Assuming X_valid and y_valid are available from previous data splitting\n",
        "xgb_predictions = model.predict(X_valid)\n",
        "xgb_predictions = np.maximum(0, np.round(xgb_predictions)).astype(int)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_valid, xgb_predictions))\n",
        "mae_xgb = mean_absolute_error(y_valid, xgb_predictions)\n",
        "\n",
        "# Re-calculate N-BEATS model predictions and evaluation metrics\n",
        "# Assuming model_nbeats, X_nbeats_valid, y_nbeats_valid, and scaler_nbeats are available\n",
        "nbeats_predictions_scaled = model_nbeats.predict(X_nbeats_valid)\n",
        "\n",
        "dummy_array_predictions = np.zeros((nbeats_predictions_scaled.shape[0], nbeats_predictions_scaled.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_predictions[:, :, 0] = nbeats_predictions_scaled\n",
        "nbeats_predictions = scaler_nbeats.inverse_transform(dummy_array_predictions)[:, :, 0]\n",
        "\n",
        "dummy_array_actuals = np.zeros((y_nbeats_valid.shape[0], y_nbeats_valid.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_actuals[:, :, 0] = y_nbeats_valid\n",
        "nbeats_actuals = scaler_nbeats.inverse_transform(dummy_array_actuals)[:, :, 0]\n",
        "\n",
        "nbeats_predictions_flat = nbeats_predictions.flatten()\n",
        "nbeats_actuals_flat = nbeats_actuals.flatten()\n",
        "\n",
        "nbeats_predictions_flat = np.maximum(0, np.round(nbeats_predictions_flat)).astype(int)\n",
        "nbeats_actuals_flat = nbeats_actuals_flat.astype(int)\n",
        "\n",
        "rmse_nbeats = np.sqrt(mean_squared_error(nbeats_actuals_flat, nbeats_predictions_flat))\n",
        "mae_nbeats = mean_absolute_error(nbeats_actuals_flat, nbeats_predictions_flat)\n",
        "\n",
        "\n",
        "# Print a comparison table or summary\n",
        "print(\"Model Performance Comparison on Validation Data:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'Model':<15} | {'RMSE':<10} | {'MAE':<10}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'XGBoost':<15} | {rmse_xgb:<10.4f} | {mae_xgb:<10.4f}\")\n",
        "print(f\"{'N-BEATS':<15} | {rmse_nbeats:<10.4f} | {mae_nbeats:<10.4f}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Briefly discuss the observed differences in performance\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"Comparing the performance metrics (RMSE and MAE) on the validation data:\")\n",
        "print(\"- The XGBoost model achieved an RMSE of {:.4f} and an MAE of {:.4f}.\".format(rmse_xgb, mae_xgb))\n",
        "print(\"- The N-BEATS model achieved an RMSE of {:.4f} and an MAE of {:.4f}.\".format(rmse_nbeats, mae_nbeats))\n",
        "print(\"\\nBased on these metrics, the XGBoost model appears to have performed better than the N-BEATS model on this validation set, exhibiting lower RMSE and MAE.\")\n",
        "print(\"Potential reasons for this difference could include:\")\n",
        "print(\"- Data Preparation and Features: The XGBoost model utilized a broader set of engineered features (including lagged and rolling statistics), while the N-BEATS model in this implementation primarily used sales, price, and basic time/categorical features within sequences.\")\n",
        "print(\"- Model Complexity and Tuning: The default or basic configuration of the N-BEATS model implemented here might not be fully optimized for this specific dataset compared to the potentially better-tuned XGBoost model parameters.\")\n",
        "print(\"- Nature of the Problem: While deep learning models like N-BEATS are powerful for sequence data, tree-based models like XGBoost are often very effective on tabular data with well-engineered features, which is how the problem was framed for XGBoost.\")\n",
        "print(\"- Computational Resources and Training Time: Deep learning models typically require more computational resources and longer training times for optimal performance, which might have been a limiting factor in this notebook environment.\")\n",
        "print(\"\\nNote: The previous LSTM attempt was evaluated on a sample item/store and is not directly comparable to the full validation set evaluations of XGBoost and N-BEATS.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46fdf062"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the XGBoost model object `model` was not defined. I need to re-train the XGBoost model before attempting to calculate its evaluation metrics and compare with the N-BEATS model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWTokBQwaUOh"
      },
      "source": [
        "# Re-train the XGBoost model\n",
        "# Assuming X_train and y_train are available from previous data splitting\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'rmse',\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'tree_method': 'hist'\n",
        "}\n",
        "\n",
        "model = XGBRegressor(**params)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Re-calculate XGBoost model predictions and evaluation metrics\n",
        "# Assuming X_valid and y_valid are available from previous data splitting\n",
        "xgb_predictions = model.predict(X_valid)\n",
        "xgb_predictions = np.maximum(0, np.round(xgb_predictions)).astype(int)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_valid, xgb_predictions))\n",
        "mae_xgb = mean_absolute_error(y_valid, xgb_predictions)\n",
        "\n",
        "# Re-calculate N-BEATS model predictions and evaluation metrics\n",
        "# Assuming model_nbeats, X_nbeats_valid, y_nbeats_valid, and scaler_nbeats are available\n",
        "nbeats_predictions_scaled = model_nbeats.predict(X_nbeats_valid)\n",
        "\n",
        "dummy_array_predictions = np.zeros((nbeats_predictions_scaled.shape[0], nbeats_predictions_scaled.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_predictions[:, :, 0] = nbeats_predictions_scaled\n",
        "nbeats_predictions = scaler_nbeats.inverse_transform(dummy_array_predictions)[:, :, 0]\n",
        "\n",
        "dummy_array_actuals = np.zeros((y_nbeats_valid.shape[0], y_nbeats_valid.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_actuals[:, :, 0] = y_nbeats_valid\n",
        "nbeats_actuals = scaler_nbeats.inverse_transform(dummy_array_actuals)[:, :, 0]\n",
        "\n",
        "nbeats_predictions_flat = nbeats_predictions.flatten()\n",
        "nbeats_actuals_flat = nbeats_actuals.flatten()\n",
        "\n",
        "nbeats_predictions_flat = np.maximum(0, np.round(nbeats_predictions_flat)).astype(int)\n",
        "nbeats_actuals_flat = nbeats_actuals_flat.astype(int)\n",
        "\n",
        "rmse_nbeats = np.sqrt(mean_squared_error(nbeats_actuals_flat, nbeats_predictions_flat))\n",
        "mae_nbeats = mean_absolute_error(nbeats_actuals_flat, nbeats_predictions_flat)\n",
        "\n",
        "\n",
        "# Print a comparison table or summary\n",
        "print(\"Model Performance Comparison on Validation Data:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'Model':<15} | {'RMSE':<10} | {'MAE':<10}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'XGBoost':<15} | {rmse_xgb:<10.4f} | {mae_xgb:<10.4f}\")\n",
        "print(f\"{'N-BEATS':<15} | {rmse_nbeats:<10.4f} | {mae_nbeats:<10.4f}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Briefly discuss the observed differences in performance\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"Comparing the performance metrics (RMSE and MAE) on the validation data:\")\n",
        "print(\"- The XGBoost model achieved an RMSE of {:.4f} and an MAE of {:.4f}.\".format(rmse_xgb, mae_xgb))\n",
        "print(\"- The N-BEATS model achieved an RMSE of {:.4f} and an MAE of {:.4f}.\".format(rmse_nbeats, mae_nbeats))\n",
        "print(\"\\nBased on these metrics, the XGBoost model appears to have performed better than the N-BEATS model on this validation set, exhibiting lower RMSE and MAE.\")\n",
        "print(\"Potential reasons for this difference could include:\")\n",
        "print(\"- Data Preparation and Features: The XGBoost model utilized a broader set of engineered features (including lagged and rolling statistics), while the N-BEATS model in this implementation primarily used sales, price, and basic time/categorical features within sequences.\")\n",
        "print(\"- Model Complexity and Tuning: The default or basic configuration of the N-BEATS model implemented here might not be fully optimized for this specific dataset compared to the potentially better-tuned XGBoost model parameters.\")\n",
        "print(\"- Nature of the Problem: While deep learning models like N-BEATS are powerful for sequence data, tree-based models like XGBoost are often very effective on tabular data with well-engineered features, which is how the problem was framed for XGBoost.\")\n",
        "print(\"- Computational Resources and Training Time: Deep learning models typically require more computational resources and longer training times for optimal performance, which might have been a limiting factor in this notebook environment.\")\n",
        "print(\"\\nNote: The previous LSTM attempt was evaluated on a sample item/store and is not directly comparable to the full validation set evaluations of XGBoost and N-BEATS.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6e6e0c0"
      },
      "source": [
        "## Integrate into dynamic pricing (optional)\n",
        "\n",
        "### Subtask:\n",
        "Integrate the forecasts from the better-performing deep learning model (if applicable) into the dynamic pricing strategy and evaluate the impact on revenue.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a44c60f3"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to integrate the N-BEATS forecasts into the dynamic pricing strategy and evaluate the impact on revenue. This requires having the trained N-BEATS model, the validation simulation data, and the calculated price elasticity. I will re-run the necessary data loading, merging, feature engineering, N-BEATS data preparation, model training, and elasticity calculation steps to ensure I have all components before simulating the dynamic pricing with N-BEATS forecasts. After that, I will calculate the revenue and compare it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfe12e2c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import gc\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Add, Subtract\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.optimize import minimize_scalar\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Define paths\n",
        "DATA_DIR = \"/content\"\n",
        "\n",
        "# Load CSVs\n",
        "sales = pd.read_csv(f\"{DATA_DIR}/sales_train_validation.csv\")\n",
        "calendar = pd.read_csv(f\"{DATA_DIR}/calendar.csv\")\n",
        "prices = pd.read_csv(f\"{DATA_DIR}/sell_prices.csv\")\n",
        "\n",
        "# Melt the sales data to long format\n",
        "id_cols = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
        "value_vars = [c for c in sales.columns if c.startswith('d_')]\n",
        "\n",
        "sales_long = sales.melt(\n",
        "    id_vars=id_cols,\n",
        "    value_vars=value_vars,\n",
        "    var_name='d',\n",
        "    value_name='sales'\n",
        ")\n",
        "\n",
        "# Merge calendar info\n",
        "merged_data = sales_long.merge(\n",
        "    calendar[['d','date','wm_yr_wk','event_name_1','event_type_1']],\n",
        "    on='d', how='left'\n",
        ")\n",
        "\n",
        "# Merge price info\n",
        "merged_data = merged_data.merge(\n",
        "    prices, on=['store_id','item_id','wm_yr_wk'], how='left'\n",
        ")\n",
        "\n",
        "# Convert 'date' column to datetime objects\n",
        "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
        "\n",
        "# Extract the day number from the 'd' column\n",
        "if 'day_num' not in merged_data.columns:\n",
        "    merged_data['day_num'] = merged_data['d'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Create additional features\n",
        "merged_data['dayofweek'] = merged_data['date'].dt.dayofweek\n",
        "merged_data['month'] = merged_data['date'].dt.month\n",
        "merged_data['year'] = merged_data['date'].dt.year\n",
        "merged_data['week'] = merged_data['date'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# Apply label encoding to categorical features\n",
        "categorical_cols = ['item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "for col in categorical_cols:\n",
        "    merged_data[col] = merged_data[col].astype('category')\n",
        "    merged_data[col] = merged_data[col].cat.codes\n",
        "\n",
        "# Define the split point using the day number (last 28 days for validation)\n",
        "split_day_num = merged_data['day_num'].max() - 28\n",
        "\n",
        "# Get the corresponding date from the calendar DataFrame\n",
        "split_date_str = calendar[calendar['d'] == f'd_{split_day_num}']['date'].iloc[0]\n",
        "split_date = pd.to_datetime(split_date_str)\n",
        "\n",
        "# Create training and validation sets based on date\n",
        "train = merged_data[merged_data['date'] < split_date].copy()\n",
        "valid = merged_data[merged_data['date'] >= split_date].copy()\n",
        "\n",
        "# Calculate overall price elasticity using the full merged_data before splitting\n",
        "elasticity_data = merged_data[['sales', 'sell_price']].copy()\n",
        "elasticity_data.dropna(subset=['sales', 'sell_price'], inplace=True)\n",
        "elasticity_data['log_sales'] = np.log(elasticity_data['sales'] + 1)\n",
        "elasticity_data['log_price'] = np.log(elasticity_data['sell_price'])\n",
        "elasticity_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "elasticity_data.dropna(subset=['log_price'], inplace=True)\n",
        "\n",
        "X_elasticity = elasticity_data[['log_price']]\n",
        "y_elasticity = elasticity_data['log_sales']\n",
        "\n",
        "model_elasticity = LinearRegression()\n",
        "model_elasticity.fit(X_elasticity, y_elasticity)\n",
        "overall_elasticity = model_elasticity.coef_[0]\n",
        "\n",
        "print(f\"Calculated Overall Price Elasticity of Demand: {overall_elasticity:.4f}\")\n",
        "\n",
        "\n",
        "# Prepare data for N-BEATS\n",
        "nbeats_features = ['sales', 'sell_price', 'dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "nbeats_target = 'sales'\n",
        "\n",
        "nbeats_data = merged_data.sort_values(by=['item_id', 'store_id', 'day_num'])[nbeats_features].copy()\n",
        "\n",
        "nbeats_data['sell_price'].fillna(0, inplace=True)\n",
        "\n",
        "for col in ['dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id']:\n",
        "    nbeats_data[col] = nbeats_data[col].astype(int)\n",
        "\n",
        "numerical_cols_nbeats = ['sales', 'sell_price']\n",
        "scaler_nbeats = MinMaxScaler()\n",
        "nbeats_data[numerical_cols_nbeats] = scaler_nbeats.fit_transform(nbeats_data[numerical_cols_nbeats])\n",
        "\n",
        "lookback_window = 90\n",
        "forecast_horizon = 28\n",
        "\n",
        "X_nbeats, y_nbeats = [], []\n",
        "groups = nbeats_data.groupby(['item_id', 'store_id'])\n",
        "\n",
        "# Determine the index for the time-based split within the N-BEATS sequences\n",
        "# This requires a more complex approach to align sequence generation with the date split\n",
        "# A simpler approach for demonstration: generate sequences from the full data and then split based on sequence index\n",
        "# However, for correct time-based validation, we need sequences where the target (y) is within the validation period.\n",
        "\n",
        "# Let's regenerate sequences focusing on the validation period for evaluation\n",
        "# For each item/store, find the starting point to generate sequences whose target falls in the validation period.\n",
        "X_nbeats_valid_seqs = []\n",
        "y_nbeats_valid_seqs = []\n",
        "valid_data_indices = [] # To map sequences back to original 'valid' dataframe indices\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values\n",
        "    sales_series = group[nbeats_target].values\n",
        "\n",
        "    # Find the index in the group that corresponds to the start of the validation period\n",
        "    valid_start_index_in_group = group[group['day_num'] >= split_day_num].index[0] - group.index[0] # Index relative to start of group\n",
        "\n",
        "    # Generate sequences for the validation period\n",
        "    # The sequence input ends at valid_start_index_in_group - 1\n",
        "    # The sequence output starts at valid_start_index_in_group\n",
        "    # We need `lookback_window` data points before the start of the validation period\n",
        "    sequence_start_index = valid_start_index_in_group - lookback_window\n",
        "    sequence_end_index = valid_start_index_in_group - 1\n",
        "\n",
        "    # Check if there's enough data for the lookback window\n",
        "    if sequence_start_index >= 0 and (sequence_end_index + forecast_horizon) < len(data_series):\n",
        "        X_nbeats_valid_seqs.append(data_series[sequence_start_index : (sequence_start_index + lookback_window), :])\n",
        "        y_nbeats_valid_seqs.append(sales_series[(sequence_start_index + lookback_window) : (sequence_start_index + lookback_window + forecast_horizon)])\n",
        "\n",
        "        # Store the original index in the 'valid' dataframe corresponding to the start of the forecast horizon\n",
        "        # This is complex as the N-BEATS sequences are aggregated across items/stores.\n",
        "        # A simpler approach for linking back: store the (item_id, store_id, start_day_num_of_forecast)\n",
        "        forecast_start_day_num = group['day_num'].iloc[sequence_start_index + lookback_window]\n",
        "        valid_data_indices.append((name[0], name[1], forecast_start_day_num))\n",
        "\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X_nbeats_valid_seqs = np.array(X_nbeats_valid_seqs)\n",
        "y_nbeats_valid_seqs = np.array(y_nbeats_valid_seqs)\n",
        "\n",
        "\n",
        "# For training, we can use sequences from the data before the validation period\n",
        "X_nbeats_train_seqs = []\n",
        "y_nbeats_train_seqs = []\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values\n",
        "    sales_series = group[nbeats_target].values\n",
        "\n",
        "    # Generate sequences where the target is before the validation period\n",
        "    # The end of the forecast horizon should be before the split_day_num\n",
        "    for i in range(len(data_series) - lookback_window - forecast_horizon + 1):\n",
        "         forecast_end_day_num = group['day_num'].iloc[i + lookback_window + forecast_horizon -1]\n",
        "         if forecast_end_day_num < split_day_num:\n",
        "            X_nbeats_train_seqs.append(data_series[i : (i + lookback_window), :])\n",
        "            y_nbeats_train_seqs.append(sales_series[(i + lookback_window) : (i + lookback_window + forecast_horizon)])\n",
        "         else:\n",
        "             # Stop generating training sequences for this group once we reach the validation period\n",
        "             break\n",
        "\n",
        "\n",
        "X_nbeats_train_seqs = np.array(X_nbeats_train_seqs)\n",
        "y_nbeats_train_seqs = np.array(y_nbeats_train_seqs)\n",
        "\n",
        "\n",
        "print(\"\\nShape of N-BEATS training input sequences (time-based split):\", X_nbeats_train_seqs.shape)\n",
        "print(\"Shape of N-BEATS training output sequences (time-based split):\", y_nbeats_train_seqs.shape)\n",
        "print(\"Shape of N-BEATS validation input sequences (time-based split):\", X_nbeats_valid_seqs.shape)\n",
        "print(\"Shape of N-BEATS validation output sequences (time-based split):\", y_nbeats_valid_seqs.shape)\n",
        "\n",
        "\n",
        "del nbeats_data\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "# Define N-BEATS block\n",
        "def nbeats_block(input_tensor, horizon, units, theta_units):\n",
        "    x = input_tensor\n",
        "    for _ in range(4):\n",
        "        x = Dense(units, activation='relu')(x)\n",
        "\n",
        "    theta = Dense(theta_units, activation='linear')(x)\n",
        "\n",
        "    forecast = Dense(horizon, activation='linear')(theta)\n",
        "    backcast = Dense(input_tensor.shape[-1], activation='linear')(theta)\n",
        "\n",
        "    return forecast, backcast\n",
        "\n",
        "# Define N-BEATS model\n",
        "def build_nbeats_model(input_shape, horizon, num_blocks, units, theta_units):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    residual_input = input_layer\n",
        "\n",
        "    forecasts = []\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        forecast, backcast = nbeats_block(residual_input, horizon, units, theta_units)\n",
        "        forecasts.append(forecast)\n",
        "        if i < num_blocks - 1:\n",
        "            residual_input = Subtract()([residual_input, backcast])\n",
        "\n",
        "    if num_blocks > 1:\n",
        "        output_layer = Add()(forecasts)\n",
        "    else:\n",
        "        output_layer = forecasts[0]\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape_nbeats = (X_nbeats_train_seqs.shape[1], X_nbeats_train_seqs.shape[2])\n",
        "forecast_horizon = y_nbeats_train_seqs.shape[1]\n",
        "num_blocks = 5\n",
        "units = 128\n",
        "theta_units = 128\n",
        "\n",
        "# Build and compile the N-BEATS model\n",
        "model_nbeats = build_nbeats_model(input_shape_nbeats, forecast_horizon, num_blocks, units, theta_units)\n",
        "model_nbeats.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the N-BEATS model\n",
        "epochs_nbeats = 1 # Reduced epochs for faster execution in notebook\n",
        "batch_size_nbeats = 256\n",
        "\n",
        "print(\"\\nStarting N-BEATS model training (time-based split)...\")\n",
        "history_nbeats = model_nbeats.fit(\n",
        "    X_nbeats_train_seqs,\n",
        "    y_nbeats_train_seqs,\n",
        "    epochs=epochs_nbeats,\n",
        "    batch_size=batch_size_nbeats,\n",
        "    validation_data=(X_nbeats_valid_seqs, y_nbeats_valid_seqs),\n",
        "    verbose=1\n",
        ")\n",
        "print(\"N-BEATS model training complete ✅\")\n",
        "\n",
        "# 2. Use the selected deep learning model (N-BEATS) to generate demand forecasts for the validation data.\n",
        "print(\"\\nGenerating N-BEATS forecasts for validation data...\")\n",
        "nbeats_predictions_scaled = model_nbeats.predict(X_nbeats_valid_seqs)\n",
        "\n",
        "# Inverse transform the predictions back to the original scale\n",
        "dummy_array_predictions = np.zeros((nbeats_predictions_scaled.shape[0], nbeats_predictions_scaled.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_predictions[:, :, 0] = nbeats_predictions_scaled\n",
        "nbeats_predictions = scaler_nbeats.inverse_transform(dummy_array_predictions)[:, :, 0]\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "nbeats_predictions = np.maximum(0, nbeats_predictions)\n",
        "\n",
        "\n",
        "# 3. Merge these deep learning forecasts with the validation simulation data.\n",
        "# The N-BEATS predictions are for sequences (item_id, store_id, start_day_of_forecast).\n",
        "# We need to map these predictions back to the individual daily sales records in the 'valid' dataframe.\n",
        "\n",
        "# Create a DataFrame from N-BEATS forecasts\n",
        "nbeats_forecast_df = pd.DataFrame({\n",
        "    'item_id': [idx[0] for idx in valid_data_indices for _ in range(forecast_horizon)],\n",
        "    'store_id': [idx[1] for idx in valid_data_indices for _ in range(forecast_horizon)],\n",
        "    'day_num': [idx[2] + d for idx in valid_data_indices for d in range(forecast_horizon)],\n",
        "    'predicted_demand_nbeats': nbeats_predictions.flatten()\n",
        "})\n",
        "\n",
        "# Merge N-BEATS forecasts with the validation data\n",
        "valid_sim_nbeats = valid.copy()\n",
        "valid_sim_nbeats = valid_sim_nbeats.merge(\n",
        "    nbeats_forecast_df,\n",
        "    on=['item_id', 'store_id', 'day_num'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Fill NaN predicted_demand_nbeats with 0 (for items/stores not in N-BEATS sequences or outside forecast horizon)\n",
        "valid_sim_nbeats['predicted_demand_nbeats'].fillna(0, inplace=True)\n",
        "\n",
        "print(\"Validation simulation data shape after merging N-BEATS forecasts:\", valid_sim_nbeats.shape)\n",
        "display(valid_sim_nbeats.head())\n",
        "\n",
        "\n",
        "# 4. Update the dynamic pricing simulation logic to use the deep learning forecasts as the base_demand.\n",
        "# 5. Run the dynamic pricing simulation with the deep learning forecasts and the previously calculated price elasticity (overall elasticity).\n",
        "\n",
        "# Use the overall elasticity for this simulation\n",
        "elasticity_for_nbeats_sim = overall_elasticity\n",
        "\n",
        "# Apply the find_optimal_price function using N-BEATS predictions as base_demand\n",
        "# Need to handle potential zero or negative predicted demand and base price\n",
        "valid_sim_nbeats['optimal_price_nbeats'] = valid_sim_nbeats.apply(\n",
        "    lambda row: find_optimal_price(row) if row['sell_price'] > 0 and row['predicted_demand_nbeats'] > 0 else row['sell_price'],\n",
        "    axis=1,\n",
        "    elasticity=elasticity_for_nbeats_sim # Pass elasticity as an argument\n",
        ")\n",
        "\n",
        "# Update find_optimal_price function to accept elasticity as an argument and use correct base_demand\n",
        "def find_optimal_price(row, elasticity):\n",
        "    base_demand = row['predicted_demand_nbeats'] # Use N-BEATS prediction as base demand\n",
        "    base_price = row['sell_price']\n",
        "\n",
        "    if base_price <= 0 or base_demand <= 0:\n",
        "        return base_price # Cannot optimize if base price or demand is zero or negative\n",
        "\n",
        "    price_bounds_individual = (max(0.1, base_price * 0.1), base_price * 2.0)\n",
        "\n",
        "    result = minimize_scalar(\n",
        "        negative_revenue,\n",
        "        bounds=price_bounds_individual,\n",
        "        args=(base_demand, base_price, elasticity),\n",
        "        method='bounded'\n",
        "    )\n",
        "    return result.x\n",
        "\n",
        "# Re-apply the function with the updated definition and N-BEATS predictions\n",
        "valid_sim_nbeats['optimal_price_nbeats'] = valid_sim_nbeats.apply(\n",
        "    find_optimal_price,\n",
        "    axis=1,\n",
        "    elasticity=elasticity_for_nbeats_sim\n",
        ")\n",
        "\n",
        "\n",
        "# Calculate estimated sales and revenue at the optimal price using N-BEATS forecasts\n",
        "valid_sim_nbeats['estimated_sales_optimal_price_nbeats'] = estimated_demand(\n",
        "    valid_sim_nbeats['optimal_price_nbeats'],\n",
        "    valid_sim_nbeats['predicted_demand_nbeats'],\n",
        "    valid_sim_nbeats['sell_price'],\n",
        "    elasticity_for_nbeats_sim\n",
        ")\n",
        "\n",
        "# Ensure estimated sales are non-negative and integer-like\n",
        "valid_sim_nbeats['estimated_sales_optimal_price_nbeats'] = np.maximum(0, np.round(valid_sim_nbeats['estimated_sales_optimal_price_nbeats'])).astype(int)\n",
        "\n",
        "valid_sim_nbeats['estimated_revenue_optimal_price_nbeats'] = valid_sim_nbeats['optimal_price_nbeats'] * valid_sim_nbeats['estimated_sales_optimal_price_nbeats']\n",
        "\n",
        "# Calculate actual revenue in the validation set (already calculated in a previous step, but recalculate to be sure)\n",
        "valid_sim_nbeats['actual_revenue'] = valid_sim_nbeats['sell_price'] * valid_sim_nbeats['sales']\n",
        "\n",
        "# 6. Calculate the total estimated revenue with this new dynamic pricing simulation using deep learning forecasts.\n",
        "total_estimated_revenue_dynamic_pricing_nbeats = valid_sim_nbeats['estimated_revenue_optimal_price_nbeats'].sum()\n",
        "\n",
        "# Get the total actual revenue (calculated previously or from valid_sim)\n",
        "# Assuming total_actual_revenue is available from the previous simulation step\n",
        "# If not, calculate it:\n",
        "total_actual_revenue = valid_sim_nbeats['actual_revenue'].sum()\n",
        "\n",
        "\n",
        "# 7. Compare the total estimated revenue with the actual total revenue and the estimated revenue from the previous simulations.\n",
        "\n",
        "# Percentage change in revenue with N-BEATS forecasts\n",
        "percentage_change_in_revenue_nbeats = ((total_estimated_revenue_dynamic_pricing_nbeats - total_actual_revenue) / total_actual_revenue) * 100 if total_actual_revenue != 0 else 0\n",
        "\n",
        "\n",
        "# 8. Print the results and discuss the potential impact and any observed differences.\n",
        "\n",
        "# Assuming total_estimated_revenue_dynamic_pricing and percentage_change_in_revenue\n",
        "# are available from the previous simulation with XGBoost forecasts\n",
        "\n",
        "print(\"\\nComparison of Dynamic Pricing Simulation Results:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Simulation':<30} | {'Total Estimated Revenue':<30} | {'% Change vs Actual':<20}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Actual (Base)':<30} | ${total_actual_revenue:<28,.2f} | {'N/A':<20}\")\n",
        "# Using variable names from previous simulation steps\n",
        "# print(f\"{'XGBoost Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing:<28,.2f} | {percentage_change_in_revenue:<.2f}%\")\n",
        "print(f\"{'N-BEATS Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing_nbeats:<28,.2f} | {percentage_change_in_revenue_nbeats:<.2f}%\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"This simulation integrated the N-BEATS deep learning model's demand forecasts into the dynamic pricing strategy, using the previously calculated overall price elasticity.\")\n",
        "print(\"The results show the potential revenue impact compared to the actual revenue during the validation period.\")\n",
        "print(\"Comparing this to the simulation using XGBoost forecasts would require having the results from that simulation available (total_estimated_revenue_dynamic_pricing and percentage_change_in_revenue).\")\n",
        "print(\"However, based on the calculated percentage change with N-BEATS forecasts, we can see the projected impact of using N-BEATS predictions for pricing decisions.\")\n",
        "print(\"\\nPotential impact and observed differences:\")\n",
        "print(\"- The change in estimated revenue will depend directly on the accuracy and scale of the N-BEATS forecasts.\")\n",
        "print(\"- If N-BEATS provides more accurate forecasts than previous models, the dynamic pricing strategy based on these forecasts should theoretically lead to better revenue optimization.\")\n",
        "print(\"- Differences in results between using XGBoost and N-BEATS forecasts highlight the sensitivity of the dynamic pricing strategy to the underlying demand forecasts.\")\n",
        "print(\"- Limitations include the accuracy of the price elasticity calculation and the simplification of the dynamic pricing model (e.g., not considering costs, competition, or inventory).\")\n",
        "print(\"\\nFurther analysis would involve a detailed comparison of the performance of different forecasting models and their subsequent impact on the dynamic pricing outcomes.\")\n",
        "\n",
        "display(valid_sim_nbeats[['id', 'date', 'sales', 'sell_price', 'predicted_demand_nbeats', 'optimal_price_nbeats', 'estimated_sales_optimal_price_nbeats', 'actual_revenue', 'estimated_revenue_optimal_price_nbeats']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cd00513"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because the 'day_num' column was not present in the `group` DataFrame within the N-BEATS data preparation loop. This is because the `nbeats_data` was created by selecting only `nbeats_features` from `merged_data`, and 'day_num' was not included in `nbeats_features`. I need to include 'day_num' in `nbeats_features` to use it for splitting the data within the groups. I also need to ensure the `find_optimal_price` function is defined before it's called in the dynamic pricing simulation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyMEA8_Zb5fB"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import gc\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Add, Subtract\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.optimize import minimize_scalar\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Define paths\n",
        "DATA_DIR = \"/content\"\n",
        "\n",
        "# Load CSVs\n",
        "sales = pd.read_csv(f\"{DATA_DIR}/sales_train_validation.csv\")\n",
        "calendar = pd.read_csv(f\"{DATA_DIR}/calendar.csv\")\n",
        "prices = pd.read_csv(f\"{DATA_DIR}/sell_prices.csv\")\n",
        "\n",
        "# Melt the sales data to long format\n",
        "id_cols = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
        "value_vars = [c for c in sales.columns if c.startswith('d_')]\n",
        "\n",
        "sales_long = sales.melt(\n",
        "    id_vars=id_cols,\n",
        "    value_vars=value_vars,\n",
        "    var_name='d',\n",
        "    value_name='sales'\n",
        ")\n",
        "\n",
        "# Merge calendar info\n",
        "merged_data = sales_long.merge(\n",
        "    calendar[['d','date','wm_yr_wk','event_name_1','event_type_1']],\n",
        "    on='d', how='left'\n",
        ")\n",
        "\n",
        "# Merge price info\n",
        "merged_data = merged_data.merge(\n",
        "    prices, on=['store_id','item_id','wm_yr_wk'], how='left'\n",
        ")\n",
        "\n",
        "# Convert 'date' column to datetime objects\n",
        "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
        "\n",
        "# Extract the day number from the 'd' column\n",
        "if 'day_num' not in merged_data.columns:\n",
        "    merged_data['day_num'] = merged_data['d'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Create additional features\n",
        "merged_data['dayofweek'] = merged_data['date'].dt.dayofweek\n",
        "merged_data['month'] = merged_data['date'].dt.month\n",
        "merged_data['year'] = merged_data['date'].dt.year\n",
        "merged_data['week'] = merged_data['date'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# Apply label encoding to categorical features\n",
        "categorical_cols = ['item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "for col in categorical_cols:\n",
        "    merged_data[col] = merged_data[col].astype('category')\n",
        "    merged_data[col] = merged_data[col].cat.codes\n",
        "\n",
        "# Define the split point using the day number (last 28 days for validation)\n",
        "split_day_num = merged_data['day_num'].max() - 28\n",
        "\n",
        "# Get the corresponding date from the calendar DataFrame\n",
        "split_date_str = calendar[calendar['d'] == f'd_{split_day_num}']['date'].iloc[0]\n",
        "split_date = pd.to_datetime(split_date_str)\n",
        "\n",
        "# Create training and validation sets based on date\n",
        "train = merged_data[merged_data['date'] < split_date].copy()\n",
        "valid = merged_data[merged_data['date'] >= split_date].copy()\n",
        "\n",
        "# Calculate overall price elasticity using the full merged_data before splitting\n",
        "elasticity_data = merged_data[['sales', 'sell_price']].copy()\n",
        "elasticity_data.dropna(subset=['sales', 'sell_price'], inplace=True)\n",
        "elasticity_data['log_sales'] = np.log(elasticity_data['sales'] + 1)\n",
        "elasticity_data['log_price'] = np.log(elasticity_data['sell_price'])\n",
        "elasticity_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "elasticity_data.dropna(subset=['log_price'], inplace=True)\n",
        "\n",
        "X_elasticity = elasticity_data[['log_price']]\n",
        "y_elasticity = elasticity_data['log_sales']\n",
        "\n",
        "model_elasticity = LinearRegression()\n",
        "model_elasticity.fit(X_elasticity, y_elasticity)\n",
        "overall_elasticity = model_elasticity.coef_[0]\n",
        "\n",
        "print(f\"Calculated Overall Price Elasticity of Demand: {overall_elasticity:.4f}\")\n",
        "\n",
        "\n",
        "# Prepare data for N-BEATS\n",
        "# Include 'day_num' in the features for splitting within groups\n",
        "nbeats_features = ['sales', 'sell_price', 'dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id', 'day_num']\n",
        "nbeats_target = 'sales'\n",
        "\n",
        "nbeats_data = merged_data.sort_values(by=['item_id', 'store_id', 'day_num'])[nbeats_features].copy()\n",
        "\n",
        "nbeats_data['sell_price'].fillna(0, inplace=True)\n",
        "\n",
        "for col in ['dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id', 'day_num']:\n",
        "    nbeats_data[col] = nbeats_data[col].astype(int)\n",
        "\n",
        "numerical_cols_nbeats = ['sales', 'sell_price']\n",
        "scaler_nbeats = MinMaxScaler()\n",
        "nbeats_data[numerical_cols_nbeats] = scaler_nbeats.fit_transform(nbeats_data[numerical_cols_nbeats])\n",
        "\n",
        "lookback_window = 90\n",
        "forecast_horizon = 28\n",
        "\n",
        "X_nbeats_valid_seqs = []\n",
        "y_nbeats_valid_seqs = []\n",
        "valid_data_indices = []\n",
        "\n",
        "groups = nbeats_data.groupby(['item_id', 'store_id'])\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values\n",
        "    sales_series = group[nbeats_target].values\n",
        "\n",
        "    valid_start_indices_in_group = group[group['day_num'] >= split_day_num].index\n",
        "    if not valid_start_indices_in_group.empty:\n",
        "        valid_start_index_in_group = valid_start_indices_in_group[0] - group.index[0]\n",
        "\n",
        "        sequence_start_index = valid_start_index_in_group - lookback_window\n",
        "        sequence_end_index = valid_start_index_in_group - 1\n",
        "\n",
        "        if sequence_start_index >= 0 and (valid_start_index_in_group + forecast_horizon -1) < len(data_series): # Check if forecast horizon is within bounds\n",
        "             X_nbeats_valid_seqs.append(data_series[sequence_start_index : (sequence_start_index + lookback_window), :])\n",
        "             y_nbeats_valid_seqs.append(sales_series[(sequence_start_index + lookback_window) : (sequence_start_index + lookback_window + forecast_horizon)])\n",
        "\n",
        "             # Store the original index in the 'valid' dataframe corresponding to the start of the forecast horizon\n",
        "             forecast_start_day_num = group['day_num'].iloc[sequence_start_index + lookback_window]\n",
        "             valid_data_indices.append((name[0], name[1], forecast_start_day_num))\n",
        "\n",
        "\n",
        "X_nbeats_valid_seqs = np.array(X_nbeats_valid_seqs)\n",
        "y_nbeats_valid_seqs = np.array(y_nbeats_valid_seqs)\n",
        "\n",
        "\n",
        "X_nbeats_train_seqs = []\n",
        "y_nbeats_train_seqs = []\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values\n",
        "    sales_series = group[nbeats_target].values\n",
        "\n",
        "    for i in range(len(data_series) - lookback_window - forecast_horizon + 1):\n",
        "         forecast_end_day_num = group['day_num'].iloc[i + lookback_window + forecast_horizon -1]\n",
        "         if forecast_end_day_num < split_day_num:\n",
        "            X_nbeats_train_seqs.append(data_series[i : (i + lookback_window), :])\n",
        "            y_nbeats_train_seqs.append(sales_series[(i + lookback_window) : (i + lookback_window + forecast_horizon)])\n",
        "         else:\n",
        "             break\n",
        "\n",
        "\n",
        "X_nbeats_train_seqs = np.array(X_nbeats_train_seqs)\n",
        "y_nbeats_train_seqs = np.array(y_nbeats_train_seqs)\n",
        "\n",
        "\n",
        "print(\"\\nShape of N-BEATS training input sequences (time-based split):\", X_nbeats_train_seqs.shape)\n",
        "print(\"Shape of N-BEATS training output sequences (time-based split):\", y_nbeats_train_seqs.shape)\n",
        "print(\"Shape of N-BEATS validation input sequences (time-based split):\", X_nbeats_valid_seqs.shape)\n",
        "print(\"Shape of N-BEATS validation output sequences (time-based split):\", y_nbeats_valid_seqs.shape)\n",
        "\n",
        "\n",
        "del nbeats_data\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "# Define N-BEATS block\n",
        "def nbeats_block(input_tensor, horizon, units, theta_units):\n",
        "    x = input_tensor\n",
        "    for _ in range(4):\n",
        "        x = Dense(units, activation='relu')(x)\n",
        "\n",
        "    theta = Dense(theta_units, activation='linear')(x)\n",
        "\n",
        "    forecast = Dense(horizon, activation='linear')(theta)\n",
        "    backcast = Dense(input_tensor.shape[-1], activation='linear')(theta)\n",
        "\n",
        "    return forecast, backcast\n",
        "\n",
        "# Define N-BEATS model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_nbeats_model(input_shape, horizon, num_blocks, units, theta_units):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    residual_input = input_layer\n",
        "\n",
        "    forecasts = []\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        forecast, backcast = nbeats_block(residual_input, horizon, units, theta_units)\n",
        "        forecasts.append(forecast)\n",
        "        if i < num_blocks - 1:\n",
        "            residual_input = Subtract()([residual_input, backcast])\n",
        "\n",
        "    if num_blocks > 1:\n",
        "        output_layer = Add()(forecasts)\n",
        "    else:\n",
        "        output_layer = forecasts[0]\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape_nbeats = (X_nbeats_train_seqs.shape[1], X_nbeats_train_seqs.shape[2])\n",
        "forecast_horizon = y_nbeats_train_seqs.shape[1]\n",
        "num_blocks = 5\n",
        "units = 128\n",
        "theta_units = 128\n",
        "\n",
        "# Build and compile the N-BEATS model\n",
        "model_nbeats = build_nbeats_model(input_shape_nbeats, forecast_horizon, num_blocks, units, theta_units)\n",
        "model_nbeats.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the N-BEATS model\n",
        "epochs_nbeats = 1 # Reduced epochs for faster execution in notebook\n",
        "batch_size_nbeats = 256\n",
        "\n",
        "print(\"\\nStarting N-BEATS model training (time-based split)...\")\n",
        "history_nbeats = model_nbeats.fit(\n",
        "    X_nbeats_train_seqs,\n",
        "    y_nbeats_train_seqs,\n",
        "    epochs=epochs_nbeats,\n",
        "    batch_size=batch_size_nbeats,\n",
        "    validation_data=(X_nbeats_valid_seqs, y_nbeats_valid_seqs),\n",
        "    verbose=1\n",
        ")\n",
        "print(\"N-BEATS model training complete ✅\")\n",
        "\n",
        "# 2. Use the selected deep learning model (N-BEATS) to generate demand forecasts for the validation data.\n",
        "print(\"\\nGenerating N-BEATS forecasts for validation data...\")\n",
        "nbeats_predictions_scaled = model_nbeats.predict(X_nbeats_valid_seqs)\n",
        "\n",
        "# Inverse transform the predictions back to the original scale\n",
        "dummy_array_predictions = np.zeros((nbeats_predictions_scaled.shape[0], nbeats_predictions_scaled.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_predictions[:, :, 0] = nbeats_predictions_scaled\n",
        "nbeats_predictions = scaler_nbeats.inverse_transform(dummy_array_predictions)[:, :, 0]\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "nbeats_predictions = np.maximum(0, nbeats_predictions)\n",
        "\n",
        "\n",
        "# 3. Merge these deep learning forecasts with the validation simulation data.\n",
        "# The N-BEATS predictions are for sequences (item_id, store_id, start_day_of_forecast).\n",
        "# We need to map these predictions back to the individual daily sales records in the 'valid' dataframe.\n",
        "\n",
        "# Create a DataFrame from N-BEATS forecasts\n",
        "nbeats_forecast_list = []\n",
        "for i, (item_id, store_id, forecast_start_day_num) in enumerate(valid_data_indices):\n",
        "    for d in range(forecast_horizon):\n",
        "        nbeats_forecast_list.append({\n",
        "            'item_id': item_id,\n",
        "            'store_id': store_id,\n",
        "            'day_num': forecast_start_day_num + d,\n",
        "            'predicted_demand_nbeats': nbeats_predictions[i, d]\n",
        "        })\n",
        "\n",
        "nbeats_forecast_df = pd.DataFrame(nbeats_forecast_list)\n",
        "\n",
        "# Merge N-BEATS forecasts with the validation data\n",
        "valid_sim_nbeats = valid.copy()\n",
        "valid_sim_nbeats = valid_sim_nbeats.merge(\n",
        "    nbeats_forecast_df,\n",
        "    on=['item_id', 'store_id', 'day_num'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Fill NaN predicted_demand_nbeats with 0 (for items/stores not in N-BEATS sequences or outside forecast horizon)\n",
        "valid_sim_nbeats['predicted_demand_nbeats'].fillna(0, inplace=True)\n",
        "\n",
        "print(\"Validation simulation data shape after merging N-BEATS forecasts:\", valid_sim_nbeats.shape)\n",
        "display(valid_sim_nbeats.head())\n",
        "\n",
        "\n",
        "# 4. Update the dynamic pricing simulation logic to use the deep learning forecasts as the base_demand.\n",
        "# 5. Run the dynamic pricing simulation with the deep learning forecasts and the previously calculated price elasticity (overall elasticity).\n",
        "\n",
        "# Use the overall elasticity for this simulation\n",
        "elasticity_for_nbeats_sim = overall_elasticity\n",
        "\n",
        "# Define the revenue and negative revenue functions again to ensure they are available\n",
        "def estimated_demand(price, base_demand, base_price, elasticity):\n",
        "    return base_demand * (price / base_price)**elasticity\n",
        "\n",
        "def revenue(price, base_demand, base_price, elasticity):\n",
        "    demand = estimated_demand(price, base_demand, base_price, elasticity)\n",
        "    return price * demand\n",
        "\n",
        "def negative_revenue(price, base_demand, base_price, elasticity):\n",
        "    return -revenue(price, base_demand, base_price, elasticity)\n",
        "\n",
        "\n",
        "# Apply the find_optimal_price function using N-BEATS predictions as base_demand\n",
        "def find_optimal_price(row, elasticity):\n",
        "    base_demand = row['predicted_demand_nbeats'] # Use N-BEATS prediction as base demand\n",
        "    base_price = row['sell_price']\n",
        "\n",
        "    if base_price <= 0 or base_demand <= 0:\n",
        "        return base_price # Cannot optimize if base price or demand is zero or negative\n",
        "\n",
        "    price_bounds_individual = (max(0.1, base_price * 0.1), base_price * 2.0)\n",
        "\n",
        "    # Use minimize_scalar to find the price that minimizes the negative revenue\n",
        "    result = minimize_scalar(\n",
        "        negative_revenue,\n",
        "        bounds=price_bounds_individual,\n",
        "        args=(base_demand, base_price, elasticity),\n",
        "        method='bounded'\n",
        "    )\n",
        "    return result.x\n",
        "\n",
        "valid_sim_nbeats['optimal_price_nbeats'] = valid_sim_nbeats.apply(\n",
        "    find_optimal_price,\n",
        "    axis=1,\n",
        "    elasticity=elasticity_for_nbeats_sim\n",
        ")\n",
        "\n",
        "\n",
        "# Calculate estimated sales and revenue at the optimal price using N-BEATS forecasts\n",
        "valid_sim_nbeats['estimated_sales_optimal_price_nbeats'] = estimated_demand(\n",
        "    valid_sim_nbeats['optimal_price_nbeats'],\n",
        "    valid_sim_nbeats['predicted_demand_nbeats'],\n",
        "    valid_sim_nbeats['sell_price'],\n",
        "    elasticity_for_nbeats_sim\n",
        ")\n",
        "\n",
        "# Ensure estimated sales are non-negative and integer-like\n",
        "valid_sim_nbeats['estimated_sales_optimal_price_nbeats'] = np.maximum(0, np.round(valid_sim_nbeats['estimated_sales_optimal_price_nbeats'])).astype(int)\n",
        "\n",
        "valid_sim_nbeats['estimated_revenue_optimal_price_nbeats'] = valid_sim_nbeats['optimal_price_nbeats'] * valid_sim_nbeats['estimated_sales_optimal_price_nbeats']\n",
        "\n",
        "# Calculate actual revenue in the validation set (already calculated in a previous step, but recalculate to be sure)\n",
        "valid_sim_nbeats['actual_revenue'] = valid_sim_nbeats['sell_price'] * valid_sim_nbeats['sales']\n",
        "\n",
        "# 6. Calculate the total estimated revenue with this new dynamic pricing simulation using deep learning forecasts.\n",
        "total_estimated_revenue_dynamic_pricing_nbeats = valid_sim_nbeats['estimated_revenue_optimal_price_nbeats'].sum()\n",
        "\n",
        "# Get the total actual revenue\n",
        "total_actual_revenue = valid_sim_nbeats['actual_revenue'].sum()\n",
        "\n",
        "\n",
        "# 7. Compare the total estimated revenue with the actual total revenue and the estimated revenue from the previous simulations.\n",
        "\n",
        "# Percentage change in revenue with N-BEATS forecasts\n",
        "percentage_change_in_revenue_nbeats = ((total_estimated_revenue_dynamic_pricing_nbeats - total_actual_revenue) / total_actual_revenue) * 100 if total_actual_revenue != 0 else 0\n",
        "\n",
        "\n",
        "# 8. Print the results and discuss the potential impact and any observed differences.\n",
        "\n",
        "# Assuming total_estimated_revenue_dynamic_pricing and percentage_change_in_revenue\n",
        "# are available from the previous simulation step (XGBoost)\n",
        "try:\n",
        "    print(\"\\nComparison of Dynamic Pricing Simulation Results:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Simulation':<30} | {'Total Estimated Revenue':<30} | {'% Change vs Actual':<20}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Actual (Base)':<30} | ${total_actual_revenue:<28,.2f} | {'N/A':<20}\")\n",
        "    print(f\"{'XGBoost Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing:<28,.2f} | {percentage_change_in_revenue:<.2f}%\")\n",
        "    print(f\"{'N-BEATS Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing_nbeats:<28,.2f} | {percentage_change_in_revenue_nbeats:<.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "except NameError:\n",
        "    print(\"\\nComparison of Dynamic Pricing Simulation Results:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Simulation':<30} | {'Total Estimated Revenue':<30} | {'% Change vs Actual':<20}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Actual (Base)':<30} | ${total_actual_revenue:<28,.2f} | {'N/A':<20}\")\n",
        "    print(f\"{'N-BEATS Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing_nbeats:<28,.2f} | {percentage_change_in_revenue_nbeats:<.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "    print(\"\\nNote: XGBoost simulation results were not available for comparison.\")\n",
        "\n",
        "\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"This simulation integrated the N-BEATS deep learning model's demand forecasts into the dynamic pricing strategy, using the previously calculated overall price elasticity.\")\n",
        "print(\"The results show the potential revenue impact compared to the actual revenue during the validation period.\")\n",
        "print(\"Comparing this to the simulation using XGBoost forecasts would require having the results from that simulation available.\")\n",
        "print(\"However, based on the calculated percentage change with N-BEATS forecasts, we can see the projected impact of using N-BEATS predictions for pricing decisions.\")\n",
        "print(\"\\nPotential impact and observed differences:\")\n",
        "print(\"- The change in estimated revenue will depend directly on the accuracy and scale of the N-BEATS forecasts.\")\n",
        "print(\"- If N-BEATS provides more accurate forecasts than previous models, the dynamic pricing strategy based on these forecasts should theoretically lead to better revenue optimization.\")\n",
        "print(\"- Differences in results between using different forecasting models highlight the sensitivity of the dynamic pricing strategy to the underlying demand forecasts.\")\n",
        "print(\"- Limitations include the accuracy of the price elasticity calculation and the simplification of the dynamic pricing model (e.g., not considering costs, competition, or inventory).\")\n",
        "print(\"\\nFurther analysis would involve a detailed comparison of the performance of different forecasting models and their subsequent impact on the dynamic pricing outcomes.\")\n",
        "\n",
        "display(valid_sim_nbeats[['id', 'date', 'sales', 'sell_price', 'predicted_demand_nbeats', 'optimal_price_nbeats', 'estimated_sales_optimal_price_nbeats', 'actual_revenue', 'estimated_revenue_optimal_price_nbeats']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1ec9d62"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block successfully prepared the data, calculated overall elasticity, prepared N-BEATS data (including 'day_num'), trained the N-BEATS model, generated forecasts for the validation period, and merged these forecasts with the validation data. The dynamic pricing simulation logic using N-BEATS forecasts and overall elasticity was implemented. Now, I need to finalize the simulation by applying the `find_optimal_price` function to calculate optimal prices and estimated revenue with N-BEATS forecasts, calculate the total estimated revenue, compare it to the actual revenue, and print the results along with a discussion. The last code block already includes the calculation and printing logic, but I need to make sure the simulation part is correctly executed. I will execute the part of the code that performs the simulation and comparison.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTtqDg_zf5HA"
      },
      "source": [
        "# 4. Update the dynamic pricing simulation logic to use the deep learning forecasts as the base_demand.\n",
        "# 5. Run the dynamic pricing simulation with the deep learning forecasts and the previously calculated price elasticity (overall elasticity).\n",
        "\n",
        "# Use the overall elasticity for this simulation\n",
        "elasticity_for_nbeats_sim = overall_elasticity\n",
        "\n",
        "# Define the revenue and negative revenue functions again to ensure they are available\n",
        "def estimated_demand(price, base_demand, base_price, elasticity):\n",
        "    # Add a small constant to base_price to avoid division by zero or log of zero\n",
        "    return base_demand * (price / (base_price + 1e-9))**elasticity\n",
        "\n",
        "def revenue(price, base_demand, base_price, elasticity):\n",
        "    demand = estimated_demand(price, base_demand, base_price, elasticity)\n",
        "    return price * demand\n",
        "\n",
        "def negative_revenue(price, base_demand, base_price, elasticity):\n",
        "    return -revenue(price, base_demand, base_price, elasticity)\n",
        "\n",
        "\n",
        "# Apply the find_optimal_price function using N-BEATS predictions as base_demand\n",
        "def find_optimal_price(row, elasticity):\n",
        "    base_demand = row['predicted_demand_nbeats'] # Use N-BEATS prediction as base demand\n",
        "    base_price = row['sell_price']\n",
        "\n",
        "    # Cannot optimize if base price is non-positive or predicted demand is non-positive\n",
        "    if base_price <= 0 or base_demand <= 0:\n",
        "        return base_price\n",
        "\n",
        "    # Ensure price bounds are valid\n",
        "    lower_bound = max(0.01, base_price * 0.1) # Ensure a minimum price above zero\n",
        "    upper_bound = base_price * 2.0\n",
        "    price_bounds_individual = (lower_bound, upper_bound)\n",
        "\n",
        "    # Use minimize_scalar to find the price that minimizes the negative revenue\n",
        "    result = minimize_scalar(\n",
        "        negative_revenue,\n",
        "        bounds=price_bounds_individual,\n",
        "        args=(base_demand, base_price, elasticity),\n",
        "        method='bounded'\n",
        "    )\n",
        "    return result.x\n",
        "\n",
        "# Apply the function to calculate optimal prices\n",
        "valid_sim_nbeats['optimal_price_nbeats'] = valid_sim_nbeats.apply(\n",
        "    find_optimal_price,\n",
        "    axis=1,\n",
        "    elasticity=elasticity_for_nbeats_sim\n",
        ")\n",
        "\n",
        "\n",
        "# Calculate estimated sales and revenue at the optimal price using N-BEATS forecasts\n",
        "valid_sim_nbeats['estimated_sales_optimal_price_nbeats'] = estimated_demand(\n",
        "    valid_sim_nbeats['optimal_price_nbeats'],\n",
        "    valid_sim_nbeats['predicted_demand_nbeats'],\n",
        "    valid_sim_nbeats['sell_price'],\n",
        "    elasticity_for_nbeats_sim\n",
        ")\n",
        "\n",
        "# Ensure estimated sales are non-negative and integer-like\n",
        "valid_sim_nbeats['estimated_sales_optimal_price_nbeats'] = np.maximum(0, np.round(valid_sim_nbeats['estimated_sales_optimal_price_nbeats'])).astype(int)\n",
        "\n",
        "valid_sim_nbeats['estimated_revenue_optimal_price_nbeats'] = valid_sim_nbeats['optimal_price_nbeats'] * valid_sim_nbeats['estimated_sales_optimal_price_nbeats']\n",
        "\n",
        "# Calculate actual revenue in the validation set\n",
        "valid_sim_nbeats['actual_revenue'] = valid_sim_nbeats['sell_price'] * valid_sim_nbeats['sales']\n",
        "\n",
        "# 6. Calculate the total estimated revenue with this new dynamic pricing simulation using deep learning forecasts.\n",
        "total_estimated_revenue_dynamic_pricing_nbeats = valid_sim_nbeats['estimated_revenue_optimal_price_nbeats'].sum()\n",
        "\n",
        "# Get the total actual revenue\n",
        "total_actual_revenue = valid_sim_nbeats['actual_revenue'].sum()\n",
        "\n",
        "\n",
        "# 7. Compare the total estimated revenue with the actual total revenue and the estimated revenue from the previous simulations.\n",
        "\n",
        "# Percentage change in revenue with N-BEATS forecasts\n",
        "percentage_change_in_revenue_nbeats = ((total_estimated_revenue_dynamic_pricing_nbeats - total_actual_revenue) / total_actual_revenue) * 100 if total_actual_revenue != 0 else 0\n",
        "\n",
        "\n",
        "# 8. Print the results and discuss the potential impact and any observed differences.\n",
        "\n",
        "# Assuming total_estimated_revenue_dynamic_pricing and percentage_change_in_revenue\n",
        "# are available from the previous simulation step (XGBoost)\n",
        "try:\n",
        "    print(\"\\nComparison of Dynamic Pricing Simulation Results:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Simulation':<30} | {'Total Estimated Revenue':<30} | {'% Change vs Actual':<20}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Actual (Base)':<30} | ${total_actual_revenue:<28,.2f} | {'N/A':<20}\")\n",
        "    # Accessing variables from previous successful execution\n",
        "    print(f\"{'XGBoost Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing:<28,.2f} | {percentage_change_in_revenue:<.2f}%\")\n",
        "    print(f\"{'N-BEATS Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing_nbeats:<28,.2f} | {percentage_change_in_revenue_nbeats:<.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "except NameError:\n",
        "    print(\"\\nComparison of Dynamic Pricing Simulation Results:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Simulation':<30} | {'Total Estimated Revenue':<30} | {'% Change vs Actual':<20}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Actual (Base)':<30} | ${total_actual_revenue:<28,.2f} | {'N/A':<20}\")\n",
        "    print(f\"{'N-BEATS Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing_nbeats:<28,.2f} | {percentage_change_in_revenue_nbeats:<.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "    print(\"\\nNote: XGBoost simulation results were not available for comparison.\")\n",
        "\n",
        "\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"This simulation integrated the N-BEATS deep learning model's demand forecasts into the dynamic pricing strategy, using the previously calculated overall price elasticity.\")\n",
        "print(\"The results show the potential revenue impact compared to the actual revenue during the validation period.\")\n",
        "print(\"Comparing this to the simulation using XGBoost forecasts would require having the results from that simulation available.\")\n",
        "print(\"However, based on the calculated percentage change with N-BEATS forecasts, we can see the projected impact of using N-BEATS predictions for pricing decisions.\")\n",
        "print(\"\\nPotential impact and observed differences:\")\n",
        "print(\"- The change in estimated revenue will depend directly on the accuracy and scale of the N-BEATS forecasts.\")\n",
        "print(\"- If N-BEATS provides more accurate forecasts than previous models, the dynamic pricing strategy based on these forecasts should theoretically lead to better revenue optimization.\")\n",
        "print(\"- Differences in results between using different forecasting models highlight the sensitivity of the dynamic pricing strategy to the underlying demand forecasts.\")\n",
        "print(\"- Limitations include the accuracy of the price elasticity calculation and the simplification of the dynamic pricing model (e.g., not considering costs, competition, or inventory).\")\n",
        "print(\"\\nFurther analysis would involve a detailed comparison of the performance of different forecasting models and their subsequent impact on the dynamic pricing outcomes.\")\n",
        "\n",
        "display(valid_sim_nbeats[['id', 'date', 'sales', 'sell_price', 'predicted_demand_nbeats', 'optimal_price_nbeats', 'estimated_sales_optimal_price_nbeats', 'actual_revenue', 'estimated_revenue_optimal_price_nbeats']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63c9f535"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because `overall_elasticity` was not defined. This variable was calculated in a previous code block that was not re-executed. I need to re-execute the code that loads and prepares the data, calculates the overall price elasticity, prepares the N-BEATS data, trains the N-BEATS model, generates N-BEATS forecasts, and then performs the dynamic pricing simulation using the calculated `overall_elasticity` and the N-BEATS forecasts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwf2g073gAfi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import gc\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Add, Subtract\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.optimize import minimize_scalar\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Define paths\n",
        "DATA_DIR = \"/content\"\n",
        "\n",
        "# Load CSVs\n",
        "sales = pd.read_csv(f\"{DATA_DIR}/sales_train_validation.csv\")\n",
        "calendar = pd.read_csv(f\"{DATA_DIR}/calendar.csv\")\n",
        "prices = pd.read_csv(f\"{DATA_DIR}/sell_prices.csv\")\n",
        "\n",
        "# Melt the sales data to long format\n",
        "id_cols = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
        "value_vars = [c for c in sales.columns if c.startswith('d_')]\n",
        "\n",
        "sales_long = sales.melt(\n",
        "    id_vars=id_cols,\n",
        "    value_vars=value_vars,\n",
        "    var_name='d',\n",
        "    value_name='sales'\n",
        ")\n",
        "\n",
        "# Merge calendar info\n",
        "merged_data = sales_long.merge(\n",
        "    calendar[['d','date','wm_yr_wk','event_name_1','event_type_1']],\n",
        "    on='d', how='left'\n",
        ")\n",
        "\n",
        "# Merge price info\n",
        "merged_data = merged_data.merge(\n",
        "    prices, on=['store_id','item_id','wm_yr_wk'], how='left'\n",
        ")\n",
        "\n",
        "# Convert 'date' column to datetime objects\n",
        "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
        "\n",
        "# Extract the day number from the 'd' column\n",
        "if 'day_num' not in merged_data.columns:\n",
        "    merged_data['day_num'] = merged_data['d'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Create additional features\n",
        "merged_data['dayofweek'] = merged_data['date'].dt.dayofweek\n",
        "merged_data['month'] = merged_data['date'].dt.month\n",
        "merged_data['year'] = merged_data['date'].dt.year\n",
        "merged_data['week'] = merged_data['date'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# Apply label encoding to categorical features\n",
        "categorical_cols = ['item_id', 'store_id', 'dept_id', 'cat_id']\n",
        "for col in categorical_cols:\n",
        "    merged_data[col] = merged_data[col].astype('category')\n",
        "    merged_data[col] = merged_data[col].cat.codes\n",
        "\n",
        "# Define the split point using the day number (last 28 days for validation)\n",
        "split_day_num = merged_data['day_num'].max() - 28\n",
        "\n",
        "# Get the corresponding date from the calendar DataFrame\n",
        "split_date_str = calendar[calendar['d'] == f'd_{split_day_num}']['date'].iloc[0]\n",
        "split_date = pd.to_datetime(split_date_str)\n",
        "\n",
        "# Create training and validation sets based on date\n",
        "train = merged_data[merged_data['date'] < split_date].copy()\n",
        "valid = merged_data[merged_data['date'] >= split_date].copy()\n",
        "\n",
        "# Calculate overall price elasticity using the full merged_data before splitting\n",
        "elasticity_data = merged_data[['sales', 'sell_price']].copy()\n",
        "elasticity_data.dropna(subset=['sales', 'sell_price'], inplace=True)\n",
        "elasticity_data['log_sales'] = np.log(elasticity_data['sales'] + 1)\n",
        "elasticity_data['log_price'] = np.log(elasticity_data['sell_price'])\n",
        "elasticity_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "elasticity_data.dropna(subset=['log_price'], inplace=True)\n",
        "\n",
        "X_elasticity = elasticity_data[['log_price']]\n",
        "y_elasticity = elasticity_data['log_sales']\n",
        "\n",
        "model_elasticity = LinearRegression()\n",
        "model_elasticity.fit(X_elasticity, y_elasticity)\n",
        "overall_elasticity = model_elasticity.coef_[0]\n",
        "\n",
        "print(f\"Calculated Overall Price Elasticity of Demand: {overall_elasticity:.4f}\")\n",
        "\n",
        "\n",
        "# Prepare data for N-BEATS\n",
        "# Include 'day_num' in the features for splitting within groups\n",
        "nbeats_features = ['sales', 'sell_price', 'dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id', 'day_num']\n",
        "nbeats_target = 'sales'\n",
        "\n",
        "nbeats_data = merged_data.sort_values(by=['item_id', 'store_id', 'day_num'])[nbeats_features].copy()\n",
        "\n",
        "nbeats_data['sell_price'].fillna(0, inplace=True)\n",
        "\n",
        "for col in ['dayofweek', 'month', 'year', 'week', 'item_id', 'store_id', 'dept_id', 'cat_id', 'day_num']:\n",
        "    nbeats_data[col] = nbeats_data[col].astype(int)\n",
        "\n",
        "numerical_cols_nbeats = ['sales', 'sell_price']\n",
        "scaler_nbeats = MinMaxScaler()\n",
        "nbeats_data[numerical_cols_nbeats] = scaler_nbeats.fit_transform(nbeats_data[numerical_cols_nbeats])\n",
        "\n",
        "lookback_window = 90\n",
        "forecast_horizon = 28\n",
        "\n",
        "X_nbeats_valid_seqs = []\n",
        "y_nbeats_valid_seqs = []\n",
        "valid_data_indices = []\n",
        "\n",
        "groups = nbeats_data.groupby(['item_id', 'store_id'])\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values\n",
        "    sales_series = group[nbeats_target].values\n",
        "\n",
        "    valid_start_indices_in_group = group[group['day_num'] >= split_day_num].index\n",
        "    if not valid_start_indices_in_group.empty:\n",
        "        valid_start_index_in_group = valid_start_indices_in_group[0] - group.index[0]\n",
        "\n",
        "        sequence_start_index = valid_start_index_in_group - lookback_window\n",
        "        sequence_end_index = valid_start_index_in_group - 1\n",
        "\n",
        "        if sequence_start_index >= 0 and (valid_start_index_in_group + forecast_horizon -1) < len(data_series): # Check if forecast horizon is within bounds\n",
        "             X_nbeats_valid_seqs.append(data_series[sequence_start_index : (sequence_start_index + lookback_window), :])\n",
        "             y_nbeats_valid_seqs.append(sales_series[(sequence_start_index + lookback_window) : (sequence_start_index + lookback_window + forecast_horizon)])\n",
        "\n",
        "             # Store the original index in the 'valid' dataframe corresponding to the start of the forecast horizon\n",
        "             forecast_start_day_num = group['day_num'].iloc[sequence_start_index + lookback_window]\n",
        "             valid_data_indices.append((name[0], name[1], forecast_start_day_num))\n",
        "\n",
        "\n",
        "X_nbeats_valid_seqs = np.array(X_nbeats_valid_seqs)\n",
        "y_nbeats_valid_seqs = np.array(y_nbeats_valid_seqs)\n",
        "\n",
        "\n",
        "X_nbeats_train_seqs = []\n",
        "y_nbeats_train_seqs = []\n",
        "\n",
        "for name, group in groups:\n",
        "    data_series = group[nbeats_features].values\n",
        "    sales_series = group[nbeats_target].values\n",
        "\n",
        "    for i in range(len(data_series) - lookback_window - forecast_horizon + 1):\n",
        "         forecast_end_day_num = group['day_num'].iloc[i + lookback_window + forecast_horizon -1]\n",
        "         if forecast_end_day_num < split_day_num:\n",
        "            X_nbeats_train_seqs.append(data_series[i : (i + lookback_window), :])\n",
        "            y_nbeats_train_seqs.append(sales_series[(i + lookback_window) : (i + lookback_window + forecast_horizon)])\n",
        "         else:\n",
        "             break\n",
        "\n",
        "\n",
        "X_nbeats_train_seqs = np.array(X_nbeats_train_seqs)\n",
        "y_nbeats_train_seqs = np.array(y_nbeats_train_seqs)\n",
        "\n",
        "\n",
        "print(\"\\nShape of N-BEATS training input sequences (time-based split):\", X_nbeats_train_seqs.shape)\n",
        "print(\"Shape of N-BEATS training output sequences (time-based split):\", y_nbeats_train_seqs.shape)\n",
        "print(\"Shape of N-BEATS validation input sequences (time-based split):\", X_nbeats_valid_seqs.shape)\n",
        "print(\"Shape of N-BEATS validation output sequences (time-based split):\", y_nbeats_valid_seqs.shape)\n",
        "\n",
        "\n",
        "del nbeats_data\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "# Define N-BEATS block\n",
        "def nbeats_block(input_tensor, horizon, units, theta_units):\n",
        "    x = input_tensor\n",
        "    for _ in range(4):\n",
        "        x = Dense(units, activation='relu')(x)\n",
        "\n",
        "    theta = Dense(theta_units, activation='linear')(x)\n",
        "\n",
        "    forecast = Dense(horizon, activation='linear')(theta)\n",
        "    backcast = Dense(input_tensor.shape[-1], activation='linear')(theta)\n",
        "\n",
        "    return forecast, backcast\n",
        "\n",
        "# Define N-BEATS model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_nbeats_model(input_shape, horizon, num_blocks, units, theta_units):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    residual_input = input_layer\n",
        "\n",
        "    forecasts = []\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        forecast, backcast = nbeats_block(residual_input, horizon, units, theta_units)\n",
        "        forecasts.append(forecast)\n",
        "        if i < num_blocks - 1:\n",
        "            residual_input = Subtract()([residual_input, backcast])\n",
        "\n",
        "    if num_blocks > 1:\n",
        "        output_layer = Add()(forecasts)\n",
        "    else:\n",
        "        output_layer = forecasts[0]\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape_nbeats = (X_nbeats_train_seqs.shape[1], X_nbeats_train_seqs.shape[2])\n",
        "forecast_horizon = y_nbeats_train_seqs.shape[1]\n",
        "num_blocks = 5\n",
        "units = 128\n",
        "theta_units = 128\n",
        "\n",
        "# Build and compile the N-BEATS model\n",
        "model_nbeats = build_nbeats_model(input_shape_nbeats, forecast_horizon, num_blocks, units, theta_units)\n",
        "model_nbeats.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the N-BEATS model\n",
        "epochs_nbeats = 1 # Reduced epochs for faster execution in notebook\n",
        "batch_size_nbeats = 256\n",
        "\n",
        "print(\"\\nStarting N-BEATS model training (time-based split)...\")\n",
        "history_nbeats = model_nbeats.fit(\n",
        "    X_nbeats_train_seqs,\n",
        "    y_nbeats_train_seqs,\n",
        "    epochs=epochs_nbeats,\n",
        "    batch_size=batch_size_nbeats,\n",
        "    validation_data=(X_nbeats_valid_seqs, y_nbeats_valid_seqs),\n",
        "    verbose=1\n",
        ")\n",
        "print(\"N-BEATS model training complete ✅\")\n",
        "\n",
        "# 2. Use the selected deep learning model (N-BEATS) to generate demand forecasts for the validation data.\n",
        "print(\"\\nGenerating N-BEATS forecasts for validation data...\")\n",
        "nbeats_predictions_scaled = model_nbeats.predict(X_nbeats_valid_seqs)\n",
        "\n",
        "# Inverse transform the predictions back to the original scale\n",
        "dummy_array_predictions = np.zeros((nbeats_predictions_scaled.shape[0], nbeats_predictions_scaled.shape[1], scaler_nbeats.n_features_in_))\n",
        "dummy_array_predictions[:, :, 0] = nbeats_predictions_scaled\n",
        "nbeats_predictions = scaler_nbeats.inverse_transform(dummy_array_predictions)[:, :, 0]\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "nbeats_predictions = np.maximum(0, nbeats_predictions)\n",
        "\n",
        "\n",
        "# 3. Merge these deep learning forecasts with the validation simulation data.\n",
        "# The N-BEATS predictions are for sequences (item_id, store_id, start_day_of_forecast).\n",
        "# We need to map these predictions back to the individual daily sales records in the 'valid' dataframe.\n",
        "\n",
        "# Create a DataFrame from N-BEATS forecasts\n",
        "nbeats_forecast_list = []\n",
        "for i, (item_id, store_id, forecast_start_day_num) in enumerate(valid_data_indices):\n",
        "    for d in range(forecast_horizon):\n",
        "        nbeats_forecast_list.append({\n",
        "            'item_id': item_id,\n",
        "            'store_id': store_id,\n",
        "            'day_num': forecast_start_day_num + d,\n",
        "            'predicted_demand_nbeats': nbeats_predictions[i, d]\n",
        "        })\n",
        "\n",
        "nbeats_forecast_df = pd.DataFrame(nbeats_forecast_list)\n",
        "\n",
        "# Merge N-BEATS forecasts with the validation data\n",
        "valid_sim_nbeats = valid.copy()\n",
        "valid_sim_nbeats = valid_sim_nbeats.merge(\n",
        "    nbeats_forecast_df,\n",
        "    on=['item_id', 'store_id', 'day_num'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Fill NaN predicted_demand_nbeats with 0 (for items/stores not in N-BEATS sequences or outside forecast horizon)\n",
        "valid_sim_nbeats['predicted_demand_nbeats'].fillna(0, inplace=True)\n",
        "\n",
        "print(\"Validation simulation data shape after merging N-BEATS forecasts:\", valid_sim_nbeats.shape)\n",
        "display(valid_sim_nbeats.head())\n",
        "\n",
        "\n",
        "# 4. Update the dynamic pricing simulation logic to use the deep learning forecasts as the base_demand.\n",
        "# 5. Run the dynamic pricing simulation with the deep learning forecasts and the previously calculated price elasticity (overall elasticity).\n",
        "\n",
        "# Use the overall elasticity for this simulation\n",
        "elasticity_for_nbeats_sim = overall_elasticity\n",
        "\n",
        "# Define the revenue and negative revenue functions again to ensure they are available\n",
        "def estimated_demand(price, base_demand, base_price, elasticity):\n",
        "    # Add a small constant to base_price to avoid division by zero or log of zero\n",
        "    return base_demand * (price / (base_price + 1e-9))**elasticity\n",
        "\n",
        "def revenue(price, base_demand, base_price, elasticity):\n",
        "    demand = estimated_demand(price, base_demand, base_price, elasticity)\n",
        "    return price * demand\n",
        "\n",
        "def negative_revenue(price, base_demand, base_price, elasticity):\n",
        "    return -revenue(price, base_demand, base_price, elasticity)\n",
        "\n",
        "\n",
        "# Apply the find_optimal_price function using N-BEATS predictions as base_demand\n",
        "def find_optimal_price(row, elasticity):\n",
        "    base_demand = row['predicted_demand_nbeats'] # Use N-BEATS prediction as base demand\n",
        "    base_price = row['sell_price']\n",
        "\n",
        "    # Cannot optimize if base price is non-positive or predicted demand is non-positive\n",
        "    if base_price <= 0 or base_demand <= 0:\n",
        "        return base_price\n",
        "\n",
        "    # Ensure price bounds are valid\n",
        "    lower_bound = max(0.01, base_price * 0.1) # Ensure a minimum price above zero\n",
        "    upper_bound = base_price * 2.0\n",
        "    price_bounds_individual = (lower_bound, upper_bound)\n",
        "\n",
        "    # Use minimize_scalar to find the price that minimizes the negative revenue\n",
        "    result = minimize_scalar(\n",
        "        negative_revenue,\n",
        "        bounds=price_bounds_individual,\n",
        "        args=(base_demand, base_price, elasticity),\n",
        "        method='bounded'\n",
        "    )\n",
        "    return result.x\n",
        "\n",
        "# Apply the function to calculate optimal prices\n",
        "valid_sim_nbeats['optimal_price_nbeats'] = valid_sim_nbeats.apply(\n",
        "    find_optimal_price,\n",
        "    axis=1,\n",
        "    elasticity=elasticity_for_nbeats_sim\n",
        ")\n",
        "\n",
        "\n",
        "# Calculate estimated sales and revenue at the optimal price using N-BEATS forecasts\n",
        "valid_sim_nbeats['estimated_sales_optimal_price_nbeats'] = estimated_demand(\n",
        "    valid_sim_nbeats['optimal_price_nbeats'],\n",
        "    valid_sim_nbeats['predicted_demand_nbeats'],\n",
        "    valid_sim_nbeats['sell_price'],\n",
        "    elasticity_for_nbeats_sim\n",
        ")\n",
        "\n",
        "# Ensure estimated sales are non-negative and integer-like\n",
        "valid_sim_nbeats['estimated_sales_optimal_price_nbeats'] = np.maximum(0, np.round(valid_sim_nbeats['estimated_sales_optimal_price_nbeats'])).astype(int)\n",
        "\n",
        "valid_sim_nbeats['estimated_revenue_optimal_price_nbeats'] = valid_sim_nbeats['optimal_price_nbeats'] * valid_sim_nbeats['estimated_sales_optimal_price_nbeats']\n",
        "\n",
        "# Calculate actual revenue in the validation set\n",
        "valid_sim_nbeats['actual_revenue'] = valid_sim_nbeats['sell_price'] * valid_sim_nbeats['sales']\n",
        "\n",
        "# 6. Calculate the total estimated revenue with this new dynamic pricing simulation using deep learning forecasts.\n",
        "total_estimated_revenue_dynamic_pricing_nbeats = valid_sim_nbeats['estimated_revenue_optimal_price_nbeats'].sum()\n",
        "\n",
        "# Get the total actual revenue\n",
        "total_actual_revenue = valid_sim_nbeats['actual_revenue'].sum()\n",
        "\n",
        "\n",
        "# 7. Compare the total estimated revenue with the actual total revenue and the estimated revenue from the previous simulations.\n",
        "\n",
        "# Percentage change in revenue with N-BEATS forecasts\n",
        "percentage_change_in_revenue_nbeats = ((total_estimated_revenue_dynamic_pricing_nbeats - total_actual_revenue) / total_actual_revenue) * 100 if total_actual_revenue != 0 else 0\n",
        "\n",
        "\n",
        "# 8. Print the results and discuss the potential impact and any observed differences.\n",
        "\n",
        "# Assuming total_estimated_revenue_dynamic_pricing and percentage_change_in_revenue\n",
        "# are available from the previous simulation step (XGBoost)\n",
        "try:\n",
        "    print(\"\\nComparison of Dynamic Pricing Simulation Results:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Simulation':<30} | {'Total Estimated Revenue':<30} | {'% Change vs Actual':<20}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Actual (Base)':<30} | ${total_actual_revenue:<28,.2f} | {'N/A':<20}\")\n",
        "    # Accessing variables from previous successful execution\n",
        "    print(f\"{'XGBoost Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing:<28,.2f} | {percentage_change_in_revenue:<.2f}%\")\n",
        "    print(f\"{'N-BEATS Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing_nbeats:<28,.2f} | {percentage_change_in_revenue_nbeats:<.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "except NameError:\n",
        "    print(\"\\nComparison of Dynamic Pricing Simulation Results:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Simulation':<30} | {'Total Estimated Revenue':<30} | {'% Change vs Actual':<20}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Actual (Base)':<30} | ${total_actual_revenue:<28,.2f} | {'N/A':<20}\")\n",
        "    print(f\"{'N-BEATS Forecasts + Overall Elasticity':<30} | ${total_estimated_revenue_dynamic_pricing_nbeats:<28,.2f} | {percentage_change_in_revenue_nbeats:<.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "    print(\"\\nNote: XGBoost simulation results were not available for comparison.\")\n",
        "\n",
        "\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"This simulation integrated the N-BEATS deep learning model's demand forecasts into the dynamic pricing strategy, using the previously calculated overall price elasticity.\")\n",
        "print(\"The results show the potential revenue impact compared to the actual revenue during the validation period.\")\n",
        "print(\"Comparing this to the simulation using XGBoost forecasts would require having the results from that simulation available.\")\n",
        "print(\"However, based on the calculated percentage change with N-BEATS forecasts, we can see the projected impact of using N-BEATS predictions for pricing decisions.\")\n",
        "print(\"\\nPotential impact and observed differences:\")\n",
        "print(\"- The change in estimated revenue will depend directly on the accuracy and scale of the N-BEATS forecasts.\")\n",
        "print(\"- If N-BEATS provides more accurate forecasts than previous models, the dynamic pricing strategy based on these forecasts should theoretically lead to better revenue optimization.\")\n",
        "print(\"- Differences in results between using different forecasting models highlight the sensitivity of the dynamic pricing strategy to the underlying demand forecasts.\")\n",
        "print(\"- Limitations include the accuracy of the price elasticity calculation and the simplification of the dynamic pricing model (e.g., not considering costs, competition, or inventory).\")\n",
        "print(\"\\nFurther analysis would involve a detailed comparison of the performance of different forecasting models and their subsequent impact on the dynamic pricing outcomes.\")\n",
        "\n",
        "display(valid_sim_nbeats[['id', 'date', 'sales', 'sell_price', 'predicted_demand_nbeats', 'optimal_price_nbeats', 'estimated_sales_optimal_price_nbeats', 'actual_revenue', 'estimated_revenue_optimal_price_nbeats']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac4907e6"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Four alternative deep learning architectures for time series forecasting were identified: Temporal Convolutional Networks (TCNs), Transformer networks, DeepAR, and N-BEATS.\n",
        "*   N-BEATS and TCNs were selected as promising architectures for exploration due to their suitability for temporal data and relatively lower complexity compared to Transformers.\n",
        "*   Data preparation for the N-BEATS model involved selecting features (sales, price, temporal, and categorical identifiers), handling missing price values by filling with 0, scaling numerical features (sales and price) using `MinMaxScaler`, and structuring the data into input sequences of 90 days and output sequences of 28 days.\n",
        "*   The prepared N-BEATS data was split into training and validation sets.\n",
        "*   A basic N-BEATS model architecture with 5 blocks and 128 units per dense layer was defined, built, and trained using the prepared data.\n",
        "*   The trained N-BEATS model achieved an RMSE of 2.8467 and an MAE of 1.5471 on the validation set.\n",
        "*   A comparison with a previously trained XGBoost model (with an RMSE of 1.5040 and MAE of 0.8632) showed that the XGBoost model performed better than the implemented N-BEATS model on the validation data.\n",
        "*   Integrating the N-BEATS forecasts into a dynamic pricing simulation using an overall price elasticity of approximately -0.2513 resulted in an estimated total revenue of approximately \\$116,905,618.03 over the validation period, which was a -18.70% change compared to the actual revenue of approximately \\$143,791,909.60.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Further investigation is needed to optimize the N-BEATS model architecture and hyperparameters, or explore other deep learning architectures like TCNs, to potentially improve forecasting performance and better compare with traditional models like XGBoost.\n",
        "*   Refining the dynamic pricing strategy by incorporating item-specific or store-specific price elasticity, considering factors like costs and inventory, and exploring more sophisticated optimization techniques could lead to a more accurate assessment of the revenue impact from deep learning forecasts.\n"
      ]
    }
  ]
}